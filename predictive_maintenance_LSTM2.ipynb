{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e4df6fb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "e4df6fb9",
        "outputId": "84b2a201-bea0-42f2-d134-cffc623a1bf9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eposition</th>\n",
              "      <th>flight_phase</th>\n",
              "      <th>flight_datetime</th>\n",
              "      <th>eng_install_date</th>\n",
              "      <th>cycles</th>\n",
              "      <th>egt_probe_average</th>\n",
              "      <th>fuel_flw</th>\n",
              "      <th>corrected_fan_spd</th>\n",
              "      <th>core_spd</th>\n",
              "      <th>zpn12p</th>\n",
              "      <th>vib_n1_1_bearing</th>\n",
              "      <th>vib_n2_1_bearing</th>\n",
              "      <th>vib_n2_turbine_frame</th>\n",
              "      <th>eng_type</th>\n",
              "      <th>eng_number</th>\n",
              "      <th>flight_datetime_c</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>flight_cycle</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>TAKEOFF</td>\n",
              "      <td>29-02-20 7:09</td>\n",
              "      <td>19-01-20 22:00</td>\n",
              "      <td>37.0</td>\n",
              "      <td>810.5125</td>\n",
              "      <td>1520.0</td>\n",
              "      <td>82.9875</td>\n",
              "      <td>103.19</td>\n",
              "      <td>79.21</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>0.275</td>\n",
              "      <td>0.700</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-29 07:09:00</td>\n",
              "      <td>2020-02-29</td>\n",
              "      <td>07:09:00</td>\n",
              "      <td>1</td>\n",
              "      <td>4501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CLIMB</td>\n",
              "      <td>29-02-20 7:10</td>\n",
              "      <td>19-01-20 22:00</td>\n",
              "      <td>38.0</td>\n",
              "      <td>851.5125</td>\n",
              "      <td>5373.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>105.20</td>\n",
              "      <td>89.15</td>\n",
              "      <td>0.1267</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.500</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-29 07:10:00</td>\n",
              "      <td>2020-02-29</td>\n",
              "      <td>07:10:00</td>\n",
              "      <td>1</td>\n",
              "      <td>4501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>TAKEOFF</td>\n",
              "      <td>29-02-20 11:33</td>\n",
              "      <td>19-01-20 22:00</td>\n",
              "      <td>38.0</td>\n",
              "      <td>876.5125</td>\n",
              "      <td>1476.0</td>\n",
              "      <td>82.9875</td>\n",
              "      <td>106.00</td>\n",
              "      <td>84.16</td>\n",
              "      <td>0.0600</td>\n",
              "      <td>0.225</td>\n",
              "      <td>0.600</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-29 11:33:00</td>\n",
              "      <td>2020-02-29</td>\n",
              "      <td>11:33:00</td>\n",
              "      <td>2</td>\n",
              "      <td>4500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>CLIMB</td>\n",
              "      <td>29-02-20 11:33</td>\n",
              "      <td>19-01-20 22:00</td>\n",
              "      <td>39.0</td>\n",
              "      <td>870.5875</td>\n",
              "      <td>5239.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>106.23</td>\n",
              "      <td>89.70</td>\n",
              "      <td>0.1267</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.450</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-29 11:33:00</td>\n",
              "      <td>2020-02-29</td>\n",
              "      <td>11:33:00</td>\n",
              "      <td>2</td>\n",
              "      <td>4500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>TAKEOFF</td>\n",
              "      <td>29-02-20 18:24</td>\n",
              "      <td>19-01-20 22:00</td>\n",
              "      <td>39.0</td>\n",
              "      <td>804.8500</td>\n",
              "      <td>1587.0</td>\n",
              "      <td>77.9703</td>\n",
              "      <td>102.90</td>\n",
              "      <td>78.20</td>\n",
              "      <td>0.1133</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.750</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-29 18:24:00</td>\n",
              "      <td>2020-02-29</td>\n",
              "      <td>18:24:00</td>\n",
              "      <td>3</td>\n",
              "      <td>4499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54105</th>\n",
              "      <td>1</td>\n",
              "      <td>CLIMB</td>\n",
              "      <td>10-09-24 1:29</td>\n",
              "      <td>24-04-24 23:00</td>\n",
              "      <td>4464.0</td>\n",
              "      <td>901.9125</td>\n",
              "      <td>5204.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>105.98</td>\n",
              "      <td>88.46</td>\n",
              "      <td>0.2200</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.725</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2024-09-10 01:29:00</td>\n",
              "      <td>2024-09-10</td>\n",
              "      <td>01:29:00</td>\n",
              "      <td>4096</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54106</th>\n",
              "      <td>1</td>\n",
              "      <td>TAKEOFF</td>\n",
              "      <td>10-09-24 8:09</td>\n",
              "      <td>24-04-24 23:00</td>\n",
              "      <td>4464.0</td>\n",
              "      <td>935.6000</td>\n",
              "      <td>1885.0</td>\n",
              "      <td>82.1850</td>\n",
              "      <td>106.98</td>\n",
              "      <td>84.63</td>\n",
              "      <td>0.0867</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.825</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2024-09-10 08:09:00</td>\n",
              "      <td>2024-09-10</td>\n",
              "      <td>08:09:00</td>\n",
              "      <td>4097</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54107</th>\n",
              "      <td>1</td>\n",
              "      <td>CLIMB</td>\n",
              "      <td>10-09-24 8:09</td>\n",
              "      <td>24-04-24 23:00</td>\n",
              "      <td>4465.0</td>\n",
              "      <td>899.2250</td>\n",
              "      <td>5173.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>106.03</td>\n",
              "      <td>88.91</td>\n",
              "      <td>0.1800</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.350</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2024-09-10 08:09:00</td>\n",
              "      <td>2024-09-10</td>\n",
              "      <td>08:09:00</td>\n",
              "      <td>4097</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54108</th>\n",
              "      <td>1</td>\n",
              "      <td>TAKEOFF</td>\n",
              "      <td>10-09-24 14:28</td>\n",
              "      <td>24-04-24 23:00</td>\n",
              "      <td>4465.0</td>\n",
              "      <td>905.3500</td>\n",
              "      <td>2982.0</td>\n",
              "      <td>79.7197</td>\n",
              "      <td>105.61</td>\n",
              "      <td>81.93</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.575</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2024-09-10 14:28:00</td>\n",
              "      <td>2024-09-10</td>\n",
              "      <td>14:28:00</td>\n",
              "      <td>4098</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54109</th>\n",
              "      <td>1</td>\n",
              "      <td>CLIMB</td>\n",
              "      <td>10-09-24 14:28</td>\n",
              "      <td>24-04-24 23:00</td>\n",
              "      <td>4466.0</td>\n",
              "      <td>912.9125</td>\n",
              "      <td>5378.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>105.70</td>\n",
              "      <td>90.07</td>\n",
              "      <td>0.1933</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.450</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2024-09-10 14:28:00</td>\n",
              "      <td>2024-09-10</td>\n",
              "      <td>14:28:00</td>\n",
              "      <td>4098</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54110 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       eposition flight_phase flight_datetime eng_install_date  cycles  \\\n",
              "0              1      TAKEOFF   29-02-20 7:09   19-01-20 22:00    37.0   \n",
              "1              1        CLIMB   29-02-20 7:10   19-01-20 22:00    38.0   \n",
              "2              1      TAKEOFF  29-02-20 11:33   19-01-20 22:00    38.0   \n",
              "3              1        CLIMB  29-02-20 11:33   19-01-20 22:00    39.0   \n",
              "4              1      TAKEOFF  29-02-20 18:24   19-01-20 22:00    39.0   \n",
              "...          ...          ...             ...              ...     ...   \n",
              "54105          1        CLIMB   10-09-24 1:29   24-04-24 23:00  4464.0   \n",
              "54106          1      TAKEOFF   10-09-24 8:09   24-04-24 23:00  4464.0   \n",
              "54107          1        CLIMB   10-09-24 8:09   24-04-24 23:00  4465.0   \n",
              "54108          1      TAKEOFF  10-09-24 14:28   24-04-24 23:00  4465.0   \n",
              "54109          1        CLIMB  10-09-24 14:28   24-04-24 23:00  4466.0   \n",
              "\n",
              "       egt_probe_average  fuel_flw  corrected_fan_spd  core_spd  zpn12p  \\\n",
              "0               810.5125    1520.0            82.9875    103.19   79.21   \n",
              "1               851.5125    5373.0                NaN    105.20   89.15   \n",
              "2               876.5125    1476.0            82.9875    106.00   84.16   \n",
              "3               870.5875    5239.0                NaN    106.23   89.70   \n",
              "4               804.8500    1587.0            77.9703    102.90   78.20   \n",
              "...                  ...       ...                ...       ...     ...   \n",
              "54105           901.9125    5204.0                NaN    105.98   88.46   \n",
              "54106           935.6000    1885.0            82.1850    106.98   84.63   \n",
              "54107           899.2250    5173.0                NaN    106.03   88.91   \n",
              "54108           905.3500    2982.0            79.7197    105.61   81.93   \n",
              "54109           912.9125    5378.0                NaN    105.70   90.07   \n",
              "\n",
              "       vib_n1_1_bearing  vib_n2_1_bearing  vib_n2_turbine_frame  eng_type  \\\n",
              "0                0.1000             0.275                 0.700         2   \n",
              "1                0.1267             0.375                 0.500         2   \n",
              "2                0.0600             0.225                 0.600         2   \n",
              "3                0.1267             0.150                 0.450         2   \n",
              "4                0.1133             0.300                 0.750         2   \n",
              "...                 ...               ...                   ...       ...   \n",
              "54105            0.2200             0.550                 0.725         2   \n",
              "54106            0.0867             0.600                 0.825         2   \n",
              "54107            0.1800             0.200                 0.350         2   \n",
              "54108            0.1400             0.375                 0.575         2   \n",
              "54109            0.1933             0.300                 0.450         2   \n",
              "\n",
              "       eng_number    flight_datetime_c        date      time  flight_cycle  \\\n",
              "0               1  2020-02-29 07:09:00  2020-02-29  07:09:00             1   \n",
              "1               1  2020-02-29 07:10:00  2020-02-29  07:10:00             1   \n",
              "2               1  2020-02-29 11:33:00  2020-02-29  11:33:00             2   \n",
              "3               1  2020-02-29 11:33:00  2020-02-29  11:33:00             2   \n",
              "4               1  2020-02-29 18:24:00  2020-02-29  18:24:00             3   \n",
              "...           ...                  ...         ...       ...           ...   \n",
              "54105           7  2024-09-10 01:29:00  2024-09-10  01:29:00          4096   \n",
              "54106           7  2024-09-10 08:09:00  2024-09-10  08:09:00          4097   \n",
              "54107           7  2024-09-10 08:09:00  2024-09-10  08:09:00          4097   \n",
              "54108           7  2024-09-10 14:28:00  2024-09-10  14:28:00          4098   \n",
              "54109           7  2024-09-10 14:28:00  2024-09-10  14:28:00          4098   \n",
              "\n",
              "        RUL  \n",
              "0      4501  \n",
              "1      4501  \n",
              "2      4500  \n",
              "3      4500  \n",
              "4      4499  \n",
              "...     ...  \n",
              "54105     2  \n",
              "54106     1  \n",
              "54107     1  \n",
              "54108     0  \n",
              "54109     0  \n",
              "\n",
              "[54110 rows x 20 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# load the data\n",
        "df = pd.read_csv('Data/engines2_data_cleaned_no_outliers_lstm.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "546139ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "546139ca",
        "outputId": "88037f9d-9262-4409-b02f-0f17da1ade24"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eposition</th>\n",
              "      <th>flight_phase</th>\n",
              "      <th>flight_datetime</th>\n",
              "      <th>eng_install_date</th>\n",
              "      <th>cycles</th>\n",
              "      <th>egt_probe_average</th>\n",
              "      <th>fuel_flw</th>\n",
              "      <th>corrected_fan_spd</th>\n",
              "      <th>core_spd</th>\n",
              "      <th>zpn12p</th>\n",
              "      <th>...</th>\n",
              "      <th>eng_number</th>\n",
              "      <th>flight_datetime_c</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>flight_cycle</th>\n",
              "      <th>RUL</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>month_sin</th>\n",
              "      <th>month_cos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>TAKEOFF</td>\n",
              "      <td>29-02-20 7:09</td>\n",
              "      <td>19-01-20 22:00</td>\n",
              "      <td>37.0</td>\n",
              "      <td>810.5125</td>\n",
              "      <td>1520.0</td>\n",
              "      <td>82.9875</td>\n",
              "      <td>103.19</td>\n",
              "      <td>79.21</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-29 07:09:00</td>\n",
              "      <td>2020-02-29</td>\n",
              "      <td>07:09:00</td>\n",
              "      <td>1</td>\n",
              "      <td>4501</td>\n",
              "      <td>0.965926</td>\n",
              "      <td>-2.588190e-01</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CLIMB</td>\n",
              "      <td>29-02-20 7:10</td>\n",
              "      <td>19-01-20 22:00</td>\n",
              "      <td>38.0</td>\n",
              "      <td>851.5125</td>\n",
              "      <td>5373.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>105.20</td>\n",
              "      <td>89.15</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-29 07:10:00</td>\n",
              "      <td>2020-02-29</td>\n",
              "      <td>07:10:00</td>\n",
              "      <td>1</td>\n",
              "      <td>4501</td>\n",
              "      <td>0.965926</td>\n",
              "      <td>-2.588190e-01</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>TAKEOFF</td>\n",
              "      <td>29-02-20 11:33</td>\n",
              "      <td>19-01-20 22:00</td>\n",
              "      <td>38.0</td>\n",
              "      <td>876.5125</td>\n",
              "      <td>1476.0</td>\n",
              "      <td>82.9875</td>\n",
              "      <td>106.00</td>\n",
              "      <td>84.16</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-29 11:33:00</td>\n",
              "      <td>2020-02-29</td>\n",
              "      <td>11:33:00</td>\n",
              "      <td>2</td>\n",
              "      <td>4500</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>-9.659258e-01</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>CLIMB</td>\n",
              "      <td>29-02-20 11:33</td>\n",
              "      <td>19-01-20 22:00</td>\n",
              "      <td>39.0</td>\n",
              "      <td>870.5875</td>\n",
              "      <td>5239.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>106.23</td>\n",
              "      <td>89.70</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-29 11:33:00</td>\n",
              "      <td>2020-02-29</td>\n",
              "      <td>11:33:00</td>\n",
              "      <td>2</td>\n",
              "      <td>4500</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>-9.659258e-01</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>TAKEOFF</td>\n",
              "      <td>29-02-20 18:24</td>\n",
              "      <td>19-01-20 22:00</td>\n",
              "      <td>39.0</td>\n",
              "      <td>804.8500</td>\n",
              "      <td>1587.0</td>\n",
              "      <td>77.9703</td>\n",
              "      <td>102.90</td>\n",
              "      <td>78.20</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-29 18:24:00</td>\n",
              "      <td>2020-02-29</td>\n",
              "      <td>18:24:00</td>\n",
              "      <td>3</td>\n",
              "      <td>4499</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54105</th>\n",
              "      <td>1</td>\n",
              "      <td>CLIMB</td>\n",
              "      <td>10-09-24 1:29</td>\n",
              "      <td>24-04-24 23:00</td>\n",
              "      <td>4464.0</td>\n",
              "      <td>901.9125</td>\n",
              "      <td>5204.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>105.98</td>\n",
              "      <td>88.46</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>2024-09-10 01:29:00</td>\n",
              "      <td>2024-09-10</td>\n",
              "      <td>01:29:00</td>\n",
              "      <td>4096</td>\n",
              "      <td>2</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>9.659258e-01</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54106</th>\n",
              "      <td>1</td>\n",
              "      <td>TAKEOFF</td>\n",
              "      <td>10-09-24 8:09</td>\n",
              "      <td>24-04-24 23:00</td>\n",
              "      <td>4464.0</td>\n",
              "      <td>935.6000</td>\n",
              "      <td>1885.0</td>\n",
              "      <td>82.1850</td>\n",
              "      <td>106.98</td>\n",
              "      <td>84.63</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>2024-09-10 08:09:00</td>\n",
              "      <td>2024-09-10</td>\n",
              "      <td>08:09:00</td>\n",
              "      <td>4097</td>\n",
              "      <td>1</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54107</th>\n",
              "      <td>1</td>\n",
              "      <td>CLIMB</td>\n",
              "      <td>10-09-24 8:09</td>\n",
              "      <td>24-04-24 23:00</td>\n",
              "      <td>4465.0</td>\n",
              "      <td>899.2250</td>\n",
              "      <td>5173.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>106.03</td>\n",
              "      <td>88.91</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>2024-09-10 08:09:00</td>\n",
              "      <td>2024-09-10</td>\n",
              "      <td>08:09:00</td>\n",
              "      <td>4097</td>\n",
              "      <td>1</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54108</th>\n",
              "      <td>1</td>\n",
              "      <td>TAKEOFF</td>\n",
              "      <td>10-09-24 14:28</td>\n",
              "      <td>24-04-24 23:00</td>\n",
              "      <td>4465.0</td>\n",
              "      <td>905.3500</td>\n",
              "      <td>2982.0</td>\n",
              "      <td>79.7197</td>\n",
              "      <td>105.61</td>\n",
              "      <td>81.93</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>2024-09-10 14:28:00</td>\n",
              "      <td>2024-09-10</td>\n",
              "      <td>14:28:00</td>\n",
              "      <td>4098</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-8.660254e-01</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54109</th>\n",
              "      <td>1</td>\n",
              "      <td>CLIMB</td>\n",
              "      <td>10-09-24 14:28</td>\n",
              "      <td>24-04-24 23:00</td>\n",
              "      <td>4466.0</td>\n",
              "      <td>912.9125</td>\n",
              "      <td>5378.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>105.70</td>\n",
              "      <td>90.07</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>2024-09-10 14:28:00</td>\n",
              "      <td>2024-09-10</td>\n",
              "      <td>14:28:00</td>\n",
              "      <td>4098</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-8.660254e-01</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54110 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       eposition flight_phase flight_datetime eng_install_date  cycles  \\\n",
              "0              1      TAKEOFF   29-02-20 7:09   19-01-20 22:00    37.0   \n",
              "1              1        CLIMB   29-02-20 7:10   19-01-20 22:00    38.0   \n",
              "2              1      TAKEOFF  29-02-20 11:33   19-01-20 22:00    38.0   \n",
              "3              1        CLIMB  29-02-20 11:33   19-01-20 22:00    39.0   \n",
              "4              1      TAKEOFF  29-02-20 18:24   19-01-20 22:00    39.0   \n",
              "...          ...          ...             ...              ...     ...   \n",
              "54105          1        CLIMB   10-09-24 1:29   24-04-24 23:00  4464.0   \n",
              "54106          1      TAKEOFF   10-09-24 8:09   24-04-24 23:00  4464.0   \n",
              "54107          1        CLIMB   10-09-24 8:09   24-04-24 23:00  4465.0   \n",
              "54108          1      TAKEOFF  10-09-24 14:28   24-04-24 23:00  4465.0   \n",
              "54109          1        CLIMB  10-09-24 14:28   24-04-24 23:00  4466.0   \n",
              "\n",
              "       egt_probe_average  fuel_flw  corrected_fan_spd  core_spd  zpn12p  ...  \\\n",
              "0               810.5125    1520.0            82.9875    103.19   79.21  ...   \n",
              "1               851.5125    5373.0                NaN    105.20   89.15  ...   \n",
              "2               876.5125    1476.0            82.9875    106.00   84.16  ...   \n",
              "3               870.5875    5239.0                NaN    106.23   89.70  ...   \n",
              "4               804.8500    1587.0            77.9703    102.90   78.20  ...   \n",
              "...                  ...       ...                ...       ...     ...  ...   \n",
              "54105           901.9125    5204.0                NaN    105.98   88.46  ...   \n",
              "54106           935.6000    1885.0            82.1850    106.98   84.63  ...   \n",
              "54107           899.2250    5173.0                NaN    106.03   88.91  ...   \n",
              "54108           905.3500    2982.0            79.7197    105.61   81.93  ...   \n",
              "54109           912.9125    5378.0                NaN    105.70   90.07  ...   \n",
              "\n",
              "       eng_number   flight_datetime_c        date      time  flight_cycle  \\\n",
              "0               1 2020-02-29 07:09:00  2020-02-29  07:09:00             1   \n",
              "1               1 2020-02-29 07:10:00  2020-02-29  07:10:00             1   \n",
              "2               1 2020-02-29 11:33:00  2020-02-29  11:33:00             2   \n",
              "3               1 2020-02-29 11:33:00  2020-02-29  11:33:00             2   \n",
              "4               1 2020-02-29 18:24:00  2020-02-29  18:24:00             3   \n",
              "...           ...                 ...         ...       ...           ...   \n",
              "54105           7 2024-09-10 01:29:00  2024-09-10  01:29:00          4096   \n",
              "54106           7 2024-09-10 08:09:00  2024-09-10  08:09:00          4097   \n",
              "54107           7 2024-09-10 08:09:00  2024-09-10  08:09:00          4097   \n",
              "54108           7 2024-09-10 14:28:00  2024-09-10  14:28:00          4098   \n",
              "54109           7 2024-09-10 14:28:00  2024-09-10  14:28:00          4098   \n",
              "\n",
              "        RUL  hour_sin      hour_cos  month_sin     month_cos  \n",
              "0      4501  0.965926 -2.588190e-01   0.866025  5.000000e-01  \n",
              "1      4501  0.965926 -2.588190e-01   0.866025  5.000000e-01  \n",
              "2      4500  0.258819 -9.659258e-01   0.866025  5.000000e-01  \n",
              "3      4500  0.258819 -9.659258e-01   0.866025  5.000000e-01  \n",
              "4      4499 -1.000000 -1.836970e-16   0.866025  5.000000e-01  \n",
              "...     ...       ...           ...        ...           ...  \n",
              "54105     2  0.258819  9.659258e-01  -1.000000 -1.836970e-16  \n",
              "54106     1  0.866025 -5.000000e-01  -1.000000 -1.836970e-16  \n",
              "54107     1  0.866025 -5.000000e-01  -1.000000 -1.836970e-16  \n",
              "54108     0 -0.500000 -8.660254e-01  -1.000000 -1.836970e-16  \n",
              "54109     0 -0.500000 -8.660254e-01  -1.000000 -1.836970e-16  \n",
              "\n",
              "[54110 rows x 24 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['flight_datetime_c'] = pd.to_datetime(df['flight_datetime'], format='%d-%m-%y %H:%M', dayfirst=True)\n",
        "\n",
        "# Extract cyclical time features\n",
        "\n",
        "df['hour'] = df['flight_datetime_c'].dt.hour\n",
        "# df['dayofweek'] = df['flight_datetime_c'].dt.dayofweek\n",
        "df['month'] = df['flight_datetime_c'].dt.month\n",
        "# df['day'] = df['flight_datetime_c'].dt.day\n",
        "\n",
        "# Encode them as sin/cos\n",
        "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "\n",
        "# df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
        "# df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
        "\n",
        "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "\n",
        "# df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)\n",
        "# df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)\n",
        "\n",
        "df.drop(columns=['hour','month'],inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e4ba2f66",
      "metadata": {
        "id": "e4ba2f66"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from tensorflow.keras.models import Sequential,load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "from tensorflow.keras.metrics import MeanSquaredError\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import regularizers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "186b693b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "186b693b",
        "outputId": "5513feb2-8d5f-44c0-d069-a79a2ac585e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eposition</th>\n",
              "      <th>egt_probe_average</th>\n",
              "      <th>fuel_flw</th>\n",
              "      <th>core_spd</th>\n",
              "      <th>zpn12p</th>\n",
              "      <th>vib_n1_1_bearing</th>\n",
              "      <th>vib_n2_1_bearing</th>\n",
              "      <th>vib_n2_turbine_frame</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>month_sin</th>\n",
              "      <th>month_cos</th>\n",
              "      <th>flight_phase_CLIMB</th>\n",
              "      <th>flight_phase_TAKEOFF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>810.5125</td>\n",
              "      <td>1520.0</td>\n",
              "      <td>103.19</td>\n",
              "      <td>79.21</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>0.275</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.965926</td>\n",
              "      <td>-2.588190e-01</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>851.5125</td>\n",
              "      <td>5373.0</td>\n",
              "      <td>105.20</td>\n",
              "      <td>89.15</td>\n",
              "      <td>0.1267</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.965926</td>\n",
              "      <td>-2.588190e-01</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>876.5125</td>\n",
              "      <td>1476.0</td>\n",
              "      <td>106.00</td>\n",
              "      <td>84.16</td>\n",
              "      <td>0.0600</td>\n",
              "      <td>0.225</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>-9.659258e-01</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>870.5875</td>\n",
              "      <td>5239.0</td>\n",
              "      <td>106.23</td>\n",
              "      <td>89.70</td>\n",
              "      <td>0.1267</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>-9.659258e-01</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>804.8500</td>\n",
              "      <td>1587.0</td>\n",
              "      <td>102.90</td>\n",
              "      <td>78.20</td>\n",
              "      <td>0.1133</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.750</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54105</th>\n",
              "      <td>1</td>\n",
              "      <td>901.9125</td>\n",
              "      <td>5204.0</td>\n",
              "      <td>105.98</td>\n",
              "      <td>88.46</td>\n",
              "      <td>0.2200</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.725</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>9.659258e-01</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54106</th>\n",
              "      <td>1</td>\n",
              "      <td>935.6000</td>\n",
              "      <td>1885.0</td>\n",
              "      <td>106.98</td>\n",
              "      <td>84.63</td>\n",
              "      <td>0.0867</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.825</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54107</th>\n",
              "      <td>1</td>\n",
              "      <td>899.2250</td>\n",
              "      <td>5173.0</td>\n",
              "      <td>106.03</td>\n",
              "      <td>88.91</td>\n",
              "      <td>0.1800</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54108</th>\n",
              "      <td>1</td>\n",
              "      <td>905.3500</td>\n",
              "      <td>2982.0</td>\n",
              "      <td>105.61</td>\n",
              "      <td>81.93</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.575</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-8.660254e-01</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54109</th>\n",
              "      <td>1</td>\n",
              "      <td>912.9125</td>\n",
              "      <td>5378.0</td>\n",
              "      <td>105.70</td>\n",
              "      <td>90.07</td>\n",
              "      <td>0.1933</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.450</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-8.660254e-01</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54110 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       eposition  egt_probe_average  fuel_flw  core_spd  zpn12p  \\\n",
              "0              1           810.5125    1520.0    103.19   79.21   \n",
              "1              1           851.5125    5373.0    105.20   89.15   \n",
              "2              1           876.5125    1476.0    106.00   84.16   \n",
              "3              1           870.5875    5239.0    106.23   89.70   \n",
              "4              1           804.8500    1587.0    102.90   78.20   \n",
              "...          ...                ...       ...       ...     ...   \n",
              "54105          1           901.9125    5204.0    105.98   88.46   \n",
              "54106          1           935.6000    1885.0    106.98   84.63   \n",
              "54107          1           899.2250    5173.0    106.03   88.91   \n",
              "54108          1           905.3500    2982.0    105.61   81.93   \n",
              "54109          1           912.9125    5378.0    105.70   90.07   \n",
              "\n",
              "       vib_n1_1_bearing  vib_n2_1_bearing  vib_n2_turbine_frame  hour_sin  \\\n",
              "0                0.1000             0.275                 0.700  0.965926   \n",
              "1                0.1267             0.375                 0.500  0.965926   \n",
              "2                0.0600             0.225                 0.600  0.258819   \n",
              "3                0.1267             0.150                 0.450  0.258819   \n",
              "4                0.1133             0.300                 0.750 -1.000000   \n",
              "...                 ...               ...                   ...       ...   \n",
              "54105            0.2200             0.550                 0.725  0.258819   \n",
              "54106            0.0867             0.600                 0.825  0.866025   \n",
              "54107            0.1800             0.200                 0.350  0.866025   \n",
              "54108            0.1400             0.375                 0.575 -0.500000   \n",
              "54109            0.1933             0.300                 0.450 -0.500000   \n",
              "\n",
              "           hour_cos  month_sin     month_cos  flight_phase_CLIMB  \\\n",
              "0     -2.588190e-01   0.866025  5.000000e-01               False   \n",
              "1     -2.588190e-01   0.866025  5.000000e-01                True   \n",
              "2     -9.659258e-01   0.866025  5.000000e-01               False   \n",
              "3     -9.659258e-01   0.866025  5.000000e-01                True   \n",
              "4     -1.836970e-16   0.866025  5.000000e-01               False   \n",
              "...             ...        ...           ...                 ...   \n",
              "54105  9.659258e-01  -1.000000 -1.836970e-16                True   \n",
              "54106 -5.000000e-01  -1.000000 -1.836970e-16               False   \n",
              "54107 -5.000000e-01  -1.000000 -1.836970e-16                True   \n",
              "54108 -8.660254e-01  -1.000000 -1.836970e-16               False   \n",
              "54109 -8.660254e-01  -1.000000 -1.836970e-16                True   \n",
              "\n",
              "       flight_phase_TAKEOFF  \n",
              "0                      True  \n",
              "1                     False  \n",
              "2                      True  \n",
              "3                     False  \n",
              "4                      True  \n",
              "...                     ...  \n",
              "54105                 False  \n",
              "54106                  True  \n",
              "54107                 False  \n",
              "54108                  True  \n",
              "54109                 False  \n",
              "\n",
              "[54110 rows x 14 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.get_dummies(df, columns=[\"flight_phase\"])\n",
        "\n",
        "#Define features\n",
        "sensor_cols = ['eposition','egt_probe_average', 'fuel_flw', 'core_spd', 'zpn12p', 'vib_n1_1_bearing', 'vib_n2_1_bearing',\n",
        "               'vib_n2_turbine_frame', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos']+ \\\n",
        "              [col for col in df.columns if col.startswith(\"flight_phase_\")]\n",
        "df[sensor_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2dad7c4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "2dad7c4f",
        "outputId": "19cb2d49-ed92-4cb5-baaa-bc03c3646c36"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eposition</th>\n",
              "      <th>egt_probe_average</th>\n",
              "      <th>fuel_flw</th>\n",
              "      <th>core_spd</th>\n",
              "      <th>zpn12p</th>\n",
              "      <th>vib_n1_1_bearing</th>\n",
              "      <th>vib_n2_1_bearing</th>\n",
              "      <th>vib_n2_turbine_frame</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>month_sin</th>\n",
              "      <th>month_cos</th>\n",
              "      <th>flight_phase_CLIMB</th>\n",
              "      <th>flight_phase_TAKEOFF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.212563</td>\n",
              "      <td>0.087984</td>\n",
              "      <td>0.316314</td>\n",
              "      <td>0.245870</td>\n",
              "      <td>0.306091</td>\n",
              "      <td>0.255814</td>\n",
              "      <td>0.430769</td>\n",
              "      <td>0.982963</td>\n",
              "      <td>0.370590</td>\n",
              "      <td>0.933013</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.441230</td>\n",
              "      <td>0.931276</td>\n",
              "      <td>0.566625</td>\n",
              "      <td>0.877382</td>\n",
              "      <td>0.387818</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.982963</td>\n",
              "      <td>0.370590</td>\n",
              "      <td>0.933013</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.580661</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.666252</td>\n",
              "      <td>0.560356</td>\n",
              "      <td>0.183655</td>\n",
              "      <td>0.209302</td>\n",
              "      <td>0.369231</td>\n",
              "      <td>0.629410</td>\n",
              "      <td>0.017037</td>\n",
              "      <td>0.933013</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.547616</td>\n",
              "      <td>0.901948</td>\n",
              "      <td>0.694894</td>\n",
              "      <td>0.912325</td>\n",
              "      <td>0.387818</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>0.276923</td>\n",
              "      <td>0.629410</td>\n",
              "      <td>0.017037</td>\n",
              "      <td>0.933013</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.180982</td>\n",
              "      <td>0.102648</td>\n",
              "      <td>0.280199</td>\n",
              "      <td>0.181703</td>\n",
              "      <td>0.346801</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.933013</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54105</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.722323</td>\n",
              "      <td>0.894288</td>\n",
              "      <td>0.663761</td>\n",
              "      <td>0.833545</td>\n",
              "      <td>0.673401</td>\n",
              "      <td>0.511628</td>\n",
              "      <td>0.446154</td>\n",
              "      <td>0.629410</td>\n",
              "      <td>0.982963</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54106</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.910206</td>\n",
              "      <td>0.167870</td>\n",
              "      <td>0.788294</td>\n",
              "      <td>0.590216</td>\n",
              "      <td>0.265381</td>\n",
              "      <td>0.558140</td>\n",
              "      <td>0.507692</td>\n",
              "      <td>0.933013</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54107</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.707334</td>\n",
              "      <td>0.887503</td>\n",
              "      <td>0.669988</td>\n",
              "      <td>0.862135</td>\n",
              "      <td>0.550964</td>\n",
              "      <td>0.186047</td>\n",
              "      <td>0.215385</td>\n",
              "      <td>0.933013</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54108</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.741495</td>\n",
              "      <td>0.407967</td>\n",
              "      <td>0.617684</td>\n",
              "      <td>0.418679</td>\n",
              "      <td>0.428528</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.353846</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.066987</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54109</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.783673</td>\n",
              "      <td>0.932370</td>\n",
              "      <td>0.628892</td>\n",
              "      <td>0.935832</td>\n",
              "      <td>0.591674</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>0.276923</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.066987</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54110 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       eposition  egt_probe_average  fuel_flw  core_spd    zpn12p  \\\n",
              "0            0.0           0.212563  0.087984  0.316314  0.245870   \n",
              "1            0.0           0.441230  0.931276  0.566625  0.877382   \n",
              "2            0.0           0.580661  0.078354  0.666252  0.560356   \n",
              "3            0.0           0.547616  0.901948  0.694894  0.912325   \n",
              "4            0.0           0.180982  0.102648  0.280199  0.181703   \n",
              "...          ...                ...       ...       ...       ...   \n",
              "54105        0.0           0.722323  0.894288  0.663761  0.833545   \n",
              "54106        0.0           0.910206  0.167870  0.788294  0.590216   \n",
              "54107        0.0           0.707334  0.887503  0.669988  0.862135   \n",
              "54108        0.0           0.741495  0.407967  0.617684  0.418679   \n",
              "54109        0.0           0.783673  0.932370  0.628892  0.935832   \n",
              "\n",
              "       vib_n1_1_bearing  vib_n2_1_bearing  vib_n2_turbine_frame  hour_sin  \\\n",
              "0              0.306091          0.255814              0.430769  0.982963   \n",
              "1              0.387818          0.348837              0.307692  0.982963   \n",
              "2              0.183655          0.209302              0.369231  0.629410   \n",
              "3              0.387818          0.139535              0.276923  0.629410   \n",
              "4              0.346801          0.279070              0.461538  0.000000   \n",
              "...                 ...               ...                   ...       ...   \n",
              "54105          0.673401          0.511628              0.446154  0.629410   \n",
              "54106          0.265381          0.558140              0.507692  0.933013   \n",
              "54107          0.550964          0.186047              0.215385  0.933013   \n",
              "54108          0.428528          0.348837              0.353846  0.250000   \n",
              "54109          0.591674          0.279070              0.276923  0.250000   \n",
              "\n",
              "       hour_cos  month_sin  month_cos  flight_phase_CLIMB  \\\n",
              "0      0.370590   0.933013       0.75                 0.0   \n",
              "1      0.370590   0.933013       0.75                 1.0   \n",
              "2      0.017037   0.933013       0.75                 0.0   \n",
              "3      0.017037   0.933013       0.75                 1.0   \n",
              "4      0.500000   0.933013       0.75                 0.0   \n",
              "...         ...        ...        ...                 ...   \n",
              "54105  0.982963   0.000000       0.50                 1.0   \n",
              "54106  0.250000   0.000000       0.50                 0.0   \n",
              "54107  0.250000   0.000000       0.50                 1.0   \n",
              "54108  0.066987   0.000000       0.50                 0.0   \n",
              "54109  0.066987   0.000000       0.50                 1.0   \n",
              "\n",
              "       flight_phase_TAKEOFF  \n",
              "0                       1.0  \n",
              "1                       0.0  \n",
              "2                       1.0  \n",
              "3                       0.0  \n",
              "4                       1.0  \n",
              "...                     ...  \n",
              "54105                   0.0  \n",
              "54106                   1.0  \n",
              "54107                   0.0  \n",
              "54108                   1.0  \n",
              "54109                   0.0  \n",
              "\n",
              "[54110 rows x 14 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scaler = MinMaxScaler()\n",
        "df[sensor_cols] = scaler.fit_transform(df[sensor_cols])\n",
        "df[sensor_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "02eeab5e",
      "metadata": {
        "id": "02eeab5e"
      },
      "outputs": [],
      "source": [
        "# --- Rolling window for LSTM (3D shape) ---\n",
        "def create_lstm_windows(data, window_size=20):\n",
        "    X, y = [], []\n",
        "    for engine_id in data['eng_number'].unique():\n",
        "        engine_df = data[data['eng_number'] == engine_id].reset_index(drop=True)\n",
        "        for i in range(len(engine_df) - window_size):\n",
        "            window = engine_df.loc[i:i+window_size-1, sensor_cols].values.astype(np.float32)\n",
        "            label = engine_df.loc[i + window_size - 1, 'RUL']\n",
        "            X.append(window)\n",
        "            y.append(label)\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "78cb3155",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78cb3155",
        "outputId": "23bf8710-5590-4179-e86d-4cfae14172e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (43204, 15, 14), y_train shape: (43204,)\n",
            "X_val shape: (5400, 15, 14), y_val shape: (5400,)\n",
            "X_test shape: (5401, 15, 14), y_test shape: (5401,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create sequence data\n",
        "X, y = create_lstm_windows(df, window_size=15)\n",
        "\n",
        "# # Train-test split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
        "\n",
        "# Initial 80/20 split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2,shuffle=True,random_state=42)\n",
        "# Further split temp into validation and test sets\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "# Check the shapes of the splits\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "94e2b3c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94e2b3c1",
        "outputId": "293e54c7-f682-4b31-98de-cca45a270d67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\marwa\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "# --- LSTM Model ---\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "model.compile(optimizer='adam', loss=MeanAbsoluteError(),metrics=[MeanSquaredError()])\n",
        "\n",
        "# --- Callbacks: EarlyStopping + ModelCheckpoint ---\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "checkpoint_cb = ModelCheckpoint(\"best_lstmv1_model.keras\",\n",
        "                                monitor='val_loss',\n",
        "                                save_best_only=True,\n",
        "                                mode='min',\n",
        "                                verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "573b608a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "573b608a",
        "outputId": "a3341669-0702-4598-8bfe-1cf00bace078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2149.7849 - mean_squared_error: 6221816.0000\n",
            "Epoch 1: val_loss improved from inf to 1604.62793, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2147.8362 - mean_squared_error: 6213243.0000 - val_loss: 1604.6279 - val_mean_squared_error: 3832793.7500\n",
            "Epoch 2/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1438.0315 - mean_squared_error: 3106489.7500\n",
            "Epoch 2: val_loss improved from 1604.62793 to 1121.40552, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1436.2416 - mean_squared_error: 3098800.0000 - val_loss: 1121.4055 - val_mean_squared_error: 1727922.0000\n",
            "Epoch 3/350\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1108.0375 - mean_squared_error: 1672254.2500\n",
            "Epoch 3: val_loss improved from 1121.40552 to 1091.83618, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1107.9725 - mean_squared_error: 1671916.5000 - val_loss: 1091.8362 - val_mean_squared_error: 1600769.5000\n",
            "Epoch 4/350\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1101.1748 - mean_squared_error: 1637096.2500\n",
            "Epoch 4: val_loss improved from 1091.83618 to 1091.37000, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1101.1256 - mean_squared_error: 1636934.5000 - val_loss: 1091.3700 - val_mean_squared_error: 1598603.3750\n",
            "Epoch 5/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1100.4200 - mean_squared_error: 1629962.1250\n",
            "Epoch 5: val_loss did not improve from 1091.37000\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1100.3761 - mean_squared_error: 1629874.6250 - val_loss: 1091.3829 - val_mean_squared_error: 1598661.5000\n",
            "Epoch 6/350\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1094.0668 - mean_squared_error: 1614791.2500\n",
            "Epoch 6: val_loss improved from 1091.37000 to 1091.36682, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1094.0776 - mean_squared_error: 1614829.2500 - val_loss: 1091.3668 - val_mean_squared_error: 1598591.0000\n",
            "Epoch 7/350\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1094.4309 - mean_squared_error: 1619982.0000\n",
            "Epoch 7: val_loss did not improve from 1091.36682\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1094.4469 - mean_squared_error: 1620008.3750 - val_loss: 1091.4133 - val_mean_squared_error: 1598809.0000\n",
            "Epoch 8/350\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1096.4691 - mean_squared_error: 1620793.3750\n",
            "Epoch 8: val_loss improved from 1091.36682 to 1091.36389, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1096.4910 - mean_squared_error: 1620854.7500 - val_loss: 1091.3639 - val_mean_squared_error: 1598578.2500\n",
            "Epoch 9/350\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1100.5842 - mean_squared_error: 1630111.7500\n",
            "Epoch 9: val_loss improved from 1091.36389 to 1091.33142, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1100.5638 - mean_squared_error: 1630077.8750 - val_loss: 1091.3314 - val_mean_squared_error: 1598437.7500\n",
            "Epoch 10/350\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1095.3157 - mean_squared_error: 1619830.7500\n",
            "Epoch 10: val_loss did not improve from 1091.33142\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1095.3207 - mean_squared_error: 1619849.8750 - val_loss: 1091.3408 - val_mean_squared_error: 1598446.0000\n",
            "Epoch 11/350\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1092.5035 - mean_squared_error: 1612761.5000\n",
            "Epoch 11: val_loss improved from 1091.33142 to 1091.32581, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1092.5316 - mean_squared_error: 1612827.2500 - val_loss: 1091.3258 - val_mean_squared_error: 1598410.0000\n",
            "Epoch 12/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1089.4829 - mean_squared_error: 1609484.3750\n",
            "Epoch 12: val_loss did not improve from 1091.32581\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1089.5618 - mean_squared_error: 1609615.5000 - val_loss: 1091.4663 - val_mean_squared_error: 1599057.8750\n",
            "Epoch 13/350\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1052.6951 - mean_squared_error: 1532773.3750\n",
            "Epoch 13: val_loss improved from 1091.32581 to 830.59473, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1052.5233 - mean_squared_error: 1532421.7500 - val_loss: 830.5947 - val_mean_squared_error: 989548.5625\n",
            "Epoch 14/350\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 561.8643 - mean_squared_error: 531502.8125\n",
            "Epoch 14: val_loss improved from 830.59473 to 330.57376, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 561.5615 - mean_squared_error: 531006.8125 - val_loss: 330.5738 - val_mean_squared_error: 197474.6250\n",
            "Epoch 15/350\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 367.6191 - mean_squared_error: 240641.2969\n",
            "Epoch 15: val_loss improved from 330.57376 to 322.82272, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 367.4769 - mean_squared_error: 240472.5469 - val_loss: 322.8227 - val_mean_squared_error: 204784.8125\n",
            "Epoch 16/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 333.3280 - mean_squared_error: 204066.5781\n",
            "Epoch 16: val_loss improved from 322.82272 to 282.80704, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 333.2177 - mean_squared_error: 203967.8906 - val_loss: 282.8070 - val_mean_squared_error: 159780.2344\n",
            "Epoch 17/350\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 306.2141 - mean_squared_error: 182881.3125\n",
            "Epoch 17: val_loss improved from 282.80704 to 228.94557, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 306.0524 - mean_squared_error: 182705.8594 - val_loss: 228.9456 - val_mean_squared_error: 114896.5078\n",
            "Epoch 18/350\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 275.8564 - mean_squared_error: 153283.0312\n",
            "Epoch 18: val_loss improved from 228.94557 to 218.66002, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 275.8326 - mean_squared_error: 153276.3281 - val_loss: 218.6600 - val_mean_squared_error: 111000.2266\n",
            "Epoch 19/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 257.8229 - mean_squared_error: 141741.3906\n",
            "Epoch 19: val_loss improved from 218.66002 to 196.61493, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 257.7313 - mean_squared_error: 141637.2500 - val_loss: 196.6149 - val_mean_squared_error: 95484.3203\n",
            "Epoch 20/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 240.8064 - mean_squared_error: 123596.1328\n",
            "Epoch 20: val_loss improved from 196.61493 to 184.85153, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 240.7718 - mean_squared_error: 123581.6250 - val_loss: 184.8515 - val_mean_squared_error: 87988.3750\n",
            "Epoch 21/350\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 235.1321 - mean_squared_error: 122508.9062\n",
            "Epoch 21: val_loss improved from 184.85153 to 145.29965, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 235.0836 - mean_squared_error: 122464.8047 - val_loss: 145.2997 - val_mean_squared_error: 55282.0547\n",
            "Epoch 22/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 222.7692 - mean_squared_error: 111374.7109\n",
            "Epoch 22: val_loss did not improve from 145.29965\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 222.7005 - mean_squared_error: 111308.5391 - val_loss: 156.2673 - val_mean_squared_error: 77221.2812\n",
            "Epoch 23/350\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 213.7851 - mean_squared_error: 105862.1250\n",
            "Epoch 23: val_loss improved from 145.29965 to 134.77841, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 213.7312 - mean_squared_error: 105799.8203 - val_loss: 134.7784 - val_mean_squared_error: 54393.8438\n",
            "Epoch 24/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 208.6608 - mean_squared_error: 99801.9922\n",
            "Epoch 24: val_loss did not improve from 134.77841\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 208.6239 - mean_squared_error: 99775.3750 - val_loss: 138.3219 - val_mean_squared_error: 59322.9609\n",
            "Epoch 25/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 192.3465 - mean_squared_error: 83278.6172\n",
            "Epoch 25: val_loss did not improve from 134.77841\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 192.3383 - mean_squared_error: 83281.8359 - val_loss: 135.1382 - val_mean_squared_error: 59128.9141\n",
            "Epoch 26/350\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 191.5958 - mean_squared_error: 87731.3750\n",
            "Epoch 26: val_loss improved from 134.77841 to 114.48424, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 191.5971 - mean_squared_error: 87731.4922 - val_loss: 114.4842 - val_mean_squared_error: 41481.1562\n",
            "Epoch 27/350\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 187.6440 - mean_squared_error: 83966.3984\n",
            "Epoch 27: val_loss did not improve from 114.48424\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 187.6441 - mean_squared_error: 83967.2734 - val_loss: 159.0954 - val_mean_squared_error: 92967.6484\n",
            "Epoch 28/350\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 182.2821 - mean_squared_error: 77694.2734\n",
            "Epoch 28: val_loss did not improve from 114.48424\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 182.2703 - mean_squared_error: 77679.9922 - val_loss: 237.9444 - val_mean_squared_error: 176182.0312\n",
            "Epoch 29/350\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 217.8694 - mean_squared_error: 124891.3203\n",
            "Epoch 29: val_loss did not improve from 114.48424\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 217.5103 - mean_squared_error: 124427.1094 - val_loss: 139.4149 - val_mean_squared_error: 69422.1172\n",
            "Epoch 30/350\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 173.9829 - mean_squared_error: 70258.1250\n",
            "Epoch 30: val_loss improved from 114.48424 to 108.04339, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 173.9674 - mean_squared_error: 70251.2500 - val_loss: 108.0434 - val_mean_squared_error: 45679.8867\n",
            "Epoch 31/350\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 172.1137 - mean_squared_error: 69539.4375\n",
            "Epoch 31: val_loss improved from 108.04339 to 93.41146, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 172.1161 - mean_squared_error: 69541.3906 - val_loss: 93.4115 - val_mean_squared_error: 32012.0977\n",
            "Epoch 32/350\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 175.6998 - mean_squared_error: 74413.8984\n",
            "Epoch 32: val_loss improved from 93.41146 to 88.44631, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 175.6881 - mean_squared_error: 74401.5938 - val_loss: 88.4463 - val_mean_squared_error: 27817.4141\n",
            "Epoch 33/350\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 173.4754 - mean_squared_error: 73610.3828\n",
            "Epoch 33: val_loss improved from 88.44631 to 85.46977, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 173.4380 - mean_squared_error: 73572.5469 - val_loss: 85.4698 - val_mean_squared_error: 21840.4102\n",
            "Epoch 34/350\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 160.8545 - mean_squared_error: 61574.5820\n",
            "Epoch 34: val_loss did not improve from 85.46977\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 160.8565 - mean_squared_error: 61574.6680 - val_loss: 97.4638 - val_mean_squared_error: 37587.4141\n",
            "Epoch 35/350\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 167.9338 - mean_squared_error: 72761.7656\n",
            "Epoch 35: val_loss did not improve from 85.46977\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 167.9252 - mean_squared_error: 72748.7812 - val_loss: 95.7737 - val_mean_squared_error: 41427.0625\n",
            "Epoch 36/350\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 159.6645 - mean_squared_error: 60312.9336\n",
            "Epoch 36: val_loss did not improve from 85.46977\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 159.6617 - mean_squared_error: 60320.3203 - val_loss: 107.8750 - val_mean_squared_error: 46574.5625\n",
            "Epoch 37/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 158.6791 - mean_squared_error: 60040.1328\n",
            "Epoch 37: val_loss improved from 85.46977 to 77.56446, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 158.6647 - mean_squared_error: 60032.0703 - val_loss: 77.5645 - val_mean_squared_error: 21016.0938\n",
            "Epoch 38/350\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 157.6254 - mean_squared_error: 60945.6406\n",
            "Epoch 38: val_loss did not improve from 77.56446\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 157.6272 - mean_squared_error: 60945.9727 - val_loss: 85.6955 - val_mean_squared_error: 29146.7871\n",
            "Epoch 39/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 155.5185 - mean_squared_error: 58629.6523\n",
            "Epoch 39: val_loss did not improve from 77.56446\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 155.5155 - mean_squared_error: 58632.8320 - val_loss: 96.1748 - val_mean_squared_error: 30278.9023\n",
            "Epoch 40/350\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 154.1207 - mean_squared_error: 57238.5039\n",
            "Epoch 40: val_loss did not improve from 77.56446\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 154.1234 - mean_squared_error: 57247.3398 - val_loss: 85.9048 - val_mean_squared_error: 35239.5039\n",
            "Epoch 41/350\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 148.3213 - mean_squared_error: 51758.4531\n",
            "Epoch 41: val_loss did not improve from 77.56446\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 148.3419 - mean_squared_error: 51778.8438 - val_loss: 93.5128 - val_mean_squared_error: 36240.8008\n",
            "Epoch 42/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 153.4097 - mean_squared_error: 56033.0859\n",
            "Epoch 42: val_loss improved from 77.56446 to 65.05338, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 153.3676 - mean_squared_error: 56004.6992 - val_loss: 65.0534 - val_mean_squared_error: 16235.5283\n",
            "Epoch 43/350\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 150.1678 - mean_squared_error: 54768.0391\n",
            "Epoch 43: val_loss did not improve from 65.05338\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 150.1579 - mean_squared_error: 54758.1875 - val_loss: 66.0668 - val_mean_squared_error: 18647.3633\n",
            "Epoch 44/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 143.5168 - mean_squared_error: 49517.6523\n",
            "Epoch 44: val_loss did not improve from 65.05338\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 143.5451 - mean_squared_error: 49544.3047 - val_loss: 75.6347 - val_mean_squared_error: 24115.0117\n",
            "Epoch 45/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 150.1092 - mean_squared_error: 57530.6875\n",
            "Epoch 45: val_loss did not improve from 65.05338\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 150.1272 - mean_squared_error: 57550.0664 - val_loss: 69.5879 - val_mean_squared_error: 20631.0215\n",
            "Epoch 46/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 143.4214 - mean_squared_error: 48987.6992\n",
            "Epoch 46: val_loss did not improve from 65.05338\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 143.4266 - mean_squared_error: 48993.6172 - val_loss: 65.3699 - val_mean_squared_error: 18457.9473\n",
            "Epoch 47/350\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 140.6120 - mean_squared_error: 45396.9609\n",
            "Epoch 47: val_loss did not improve from 65.05338\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 140.6643 - mean_squared_error: 45463.0352 - val_loss: 70.0909 - val_mean_squared_error: 23128.0371\n",
            "Epoch 48/350\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 139.5792 - mean_squared_error: 45937.2891\n",
            "Epoch 48: val_loss did not improve from 65.05338\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 139.5819 - mean_squared_error: 45940.3281 - val_loss: 74.5207 - val_mean_squared_error: 26367.8203\n",
            "Epoch 49/350\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 142.6839 - mean_squared_error: 49206.6172\n",
            "Epoch 49: val_loss did not improve from 65.05338\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 142.6714 - mean_squared_error: 49196.8203 - val_loss: 78.8155 - val_mean_squared_error: 25880.8750\n",
            "Epoch 50/350\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 141.1387 - mean_squared_error: 47955.0156\n",
            "Epoch 50: val_loss did not improve from 65.05338\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 141.1171 - mean_squared_error: 47949.0391 - val_loss: 68.7586 - val_mean_squared_error: 22164.1465\n",
            "Epoch 51/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 138.1090 - mean_squared_error: 45540.1797\n",
            "Epoch 51: val_loss did not improve from 65.05338\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 138.1050 - mean_squared_error: 45540.0391 - val_loss: 117.6174 - val_mean_squared_error: 71954.7734\n",
            "Epoch 52/350\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 145.5296 - mean_squared_error: 57398.0742\n",
            "Epoch 52: val_loss did not improve from 65.05338\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 145.5008 - mean_squared_error: 57359.1914 - val_loss: 90.3232 - val_mean_squared_error: 53578.7812\n",
            "Epoch 53/350\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 201.8682 - mean_squared_error: 132418.2500\n",
            "Epoch 53: val_loss improved from 65.05338 to 55.63166, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 201.1629 - mean_squared_error: 131466.5000 - val_loss: 55.6317 - val_mean_squared_error: 14483.4990\n",
            "Epoch 54/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 132.5913 - mean_squared_error: 40605.7812\n",
            "Epoch 54: val_loss did not improve from 55.63166\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 132.5865 - mean_squared_error: 40608.9297 - val_loss: 58.3421 - val_mean_squared_error: 15652.1455\n",
            "Epoch 55/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 133.0674 - mean_squared_error: 42944.1250\n",
            "Epoch 55: val_loss did not improve from 55.63166\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 133.0583 - mean_squared_error: 42935.2773 - val_loss: 66.5700 - val_mean_squared_error: 17427.0762\n",
            "Epoch 56/350\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 135.5461 - mean_squared_error: 45153.3164\n",
            "Epoch 56: val_loss did not improve from 55.63166\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 135.5312 - mean_squared_error: 45138.9258 - val_loss: 69.3808 - val_mean_squared_error: 20583.2715\n",
            "Epoch 57/350\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 130.1869 - mean_squared_error: 39726.1094\n",
            "Epoch 57: val_loss did not improve from 55.63166\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 130.1620 - mean_squared_error: 39713.9414 - val_loss: 71.0789 - val_mean_squared_error: 26463.8770\n",
            "Epoch 58/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 130.7479 - mean_squared_error: 41196.6055\n",
            "Epoch 58: val_loss did not improve from 55.63166\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 130.7598 - mean_squared_error: 41206.0938 - val_loss: 78.4520 - val_mean_squared_error: 29388.0977\n",
            "Epoch 59/350\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 138.5970 - mean_squared_error: 51534.3594\n",
            "Epoch 59: val_loss did not improve from 55.63166\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 138.5901 - mean_squared_error: 51529.6602 - val_loss: 57.1043 - val_mean_squared_error: 13999.1562\n",
            "Epoch 60/350\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 128.4754 - mean_squared_error: 40076.0547\n",
            "Epoch 60: val_loss did not improve from 55.63166\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 128.4821 - mean_squared_error: 40087.0898 - val_loss: 59.2109 - val_mean_squared_error: 16479.4160\n",
            "Epoch 61/350\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 127.0191 - mean_squared_error: 38463.2969\n",
            "Epoch 61: val_loss did not improve from 55.63166\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 127.0189 - mean_squared_error: 38464.5195 - val_loss: 68.9925 - val_mean_squared_error: 23463.6035\n",
            "Epoch 62/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 128.0240 - mean_squared_error: 40608.0664\n",
            "Epoch 62: val_loss did not improve from 55.63166\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 128.0162 - mean_squared_error: 40600.4258 - val_loss: 83.3048 - val_mean_squared_error: 41510.5234\n",
            "Epoch 63/350\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 130.7628 - mean_squared_error: 43072.4141\n",
            "Epoch 63: val_loss did not improve from 55.63166\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 130.7538 - mean_squared_error: 43068.7656 - val_loss: 61.5070 - val_mean_squared_error: 18357.5781\n",
            "Epoch 64/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 130.7887 - mean_squared_error: 44653.6914\n",
            "Epoch 64: val_loss did not improve from 55.63166\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 130.7585 - mean_squared_error: 44617.4297 - val_loss: 63.5613 - val_mean_squared_error: 22033.5059\n",
            "Epoch 65/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 126.3719 - mean_squared_error: 40218.8281\n",
            "Epoch 65: val_loss did not improve from 55.63166\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 126.3617 - mean_squared_error: 40217.9180 - val_loss: 62.6557 - val_mean_squared_error: 21808.0332\n",
            "Epoch 66/350\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 125.1960 - mean_squared_error: 39238.9805\n",
            "Epoch 66: val_loss improved from 55.63166 to 54.01150, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 125.1940 - mean_squared_error: 39236.1602 - val_loss: 54.0115 - val_mean_squared_error: 13657.0508\n",
            "Epoch 67/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 119.3327 - mean_squared_error: 34465.5742\n",
            "Epoch 67: val_loss improved from 54.01150 to 51.64797, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 119.3532 - mean_squared_error: 34485.7109 - val_loss: 51.6480 - val_mean_squared_error: 13490.9277\n",
            "Epoch 68/350\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 124.9035 - mean_squared_error: 40254.9805\n",
            "Epoch 68: val_loss did not improve from 51.64797\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 124.8889 - mean_squared_error: 40239.1641 - val_loss: 59.8248 - val_mean_squared_error: 20034.2012\n",
            "Epoch 69/350\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 125.7357 - mean_squared_error: 40718.7656\n",
            "Epoch 69: val_loss improved from 51.64797 to 47.60078, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 125.7311 - mean_squared_error: 40714.8828 - val_loss: 47.6008 - val_mean_squared_error: 8887.0596\n",
            "Epoch 70/350\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 118.3219 - mean_squared_error: 33863.9922\n",
            "Epoch 70: val_loss did not improve from 47.60078\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 118.3432 - mean_squared_error: 33887.3203 - val_loss: 57.7165 - val_mean_squared_error: 14207.3799\n",
            "Epoch 71/350\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 118.3616 - mean_squared_error: 34198.9219\n",
            "Epoch 71: val_loss did not improve from 47.60078\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 118.3603 - mean_squared_error: 34198.6133 - val_loss: 72.0139 - val_mean_squared_error: 34188.3477\n",
            "Epoch 72/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 126.1925 - mean_squared_error: 45331.6055\n",
            "Epoch 72: val_loss did not improve from 47.60078\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 126.1490 - mean_squared_error: 45276.2188 - val_loss: 66.0245 - val_mean_squared_error: 19870.6660\n",
            "Epoch 73/350\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 116.6128 - mean_squared_error: 33260.2617\n",
            "Epoch 73: val_loss did not improve from 47.60078\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 116.5999 - mean_squared_error: 33248.0977 - val_loss: 50.2455 - val_mean_squared_error: 10497.7012\n",
            "Epoch 74/350\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 115.5802 - mean_squared_error: 31618.4629\n",
            "Epoch 74: val_loss improved from 47.60078 to 47.14558, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 115.5857 - mean_squared_error: 31628.3984 - val_loss: 47.1456 - val_mean_squared_error: 10273.4434\n",
            "Epoch 75/350\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 121.3397 - mean_squared_error: 40090.6211\n",
            "Epoch 75: val_loss did not improve from 47.14558\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 121.3220 - mean_squared_error: 40069.6680 - val_loss: 66.4019 - val_mean_squared_error: 15135.7275\n",
            "Epoch 76/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 112.2780 - mean_squared_error: 29755.7227\n",
            "Epoch 76: val_loss did not improve from 47.14558\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 112.2944 - mean_squared_error: 29781.8906 - val_loss: 93.0881 - val_mean_squared_error: 48502.0391\n",
            "Epoch 77/350\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 116.3675 - mean_squared_error: 33870.4336\n",
            "Epoch 77: val_loss did not improve from 47.14558\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 116.3607 - mean_squared_error: 33865.4453 - val_loss: 55.8557 - val_mean_squared_error: 13372.1807\n",
            "Epoch 78/350\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 112.0920 - mean_squared_error: 30982.9688\n",
            "Epoch 78: val_loss did not improve from 47.14558\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 112.0935 - mean_squared_error: 30983.3574 - val_loss: 71.6774 - val_mean_squared_error: 15444.1709\n",
            "Epoch 79/350\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 117.8437 - mean_squared_error: 37638.9609\n",
            "Epoch 79: val_loss did not improve from 47.14558\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 117.8398 - mean_squared_error: 37634.8945 - val_loss: 53.8320 - val_mean_squared_error: 16072.1973\n",
            "Epoch 80/350\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 111.7404 - mean_squared_error: 30867.5352\n",
            "Epoch 80: val_loss improved from 47.14558 to 45.70548, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 111.7182 - mean_squared_error: 30847.7812 - val_loss: 45.7055 - val_mean_squared_error: 9200.2812\n",
            "Epoch 81/350\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 108.3588 - mean_squared_error: 28421.4609\n",
            "Epoch 81: val_loss improved from 45.70548 to 44.58733, saving model to best_lstmv1_model.keras\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 108.3764 - mean_squared_error: 28432.4336 - val_loss: 44.5873 - val_mean_squared_error: 7977.5859\n",
            "Epoch 82/350\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 109.3272 - mean_squared_error: 29897.1816\n",
            "Epoch 82: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 109.3423 - mean_squared_error: 29915.3906 - val_loss: 59.9260 - val_mean_squared_error: 18920.0605\n",
            "Epoch 83/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 108.2844 - mean_squared_error: 28770.4453\n",
            "Epoch 83: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 108.2985 - mean_squared_error: 28786.0508 - val_loss: 57.6668 - val_mean_squared_error: 15659.3359\n",
            "Epoch 84/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 109.1392 - mean_squared_error: 29124.8770\n",
            "Epoch 84: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 109.1581 - mean_squared_error: 29157.2500 - val_loss: 48.6900 - val_mean_squared_error: 12113.5449\n",
            "Epoch 85/350\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 112.8980 - mean_squared_error: 35036.1172\n",
            "Epoch 85: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 112.8807 - mean_squared_error: 35016.8945 - val_loss: 55.5910 - val_mean_squared_error: 11410.5879\n",
            "Epoch 86/350\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 107.1458 - mean_squared_error: 29526.9844\n",
            "Epoch 86: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 107.1468 - mean_squared_error: 29529.2051 - val_loss: 57.6738 - val_mean_squared_error: 17551.0566\n",
            "Epoch 87/350\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 109.8723 - mean_squared_error: 34724.8086\n",
            "Epoch 87: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 109.8402 - mean_squared_error: 34676.1484 - val_loss: 100.7584 - val_mean_squared_error: 67539.8594\n",
            "Epoch 88/350\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 126.0730 - mean_squared_error: 52328.3242\n",
            "Epoch 88: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 125.8367 - mean_squared_error: 52042.0391 - val_loss: 53.5189 - val_mean_squared_error: 14752.7930\n",
            "Epoch 89/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 106.6705 - mean_squared_error: 30497.7988\n",
            "Epoch 89: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 106.6970 - mean_squared_error: 30538.6035 - val_loss: 52.5276 - val_mean_squared_error: 9792.7002\n",
            "Epoch 90/350\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 102.1316 - mean_squared_error: 25451.8848\n",
            "Epoch 90: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 102.1451 - mean_squared_error: 25475.7051 - val_loss: 59.9141 - val_mean_squared_error: 25483.5352\n",
            "Epoch 91/350\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 107.8049 - mean_squared_error: 33270.3320\n",
            "Epoch 91: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 107.7912 - mean_squared_error: 33248.5664 - val_loss: 46.1389 - val_mean_squared_error: 10151.4014\n",
            "Epoch 92/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 101.6569 - mean_squared_error: 25227.9102\n",
            "Epoch 92: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 101.6668 - mean_squared_error: 25244.5254 - val_loss: 46.4324 - val_mean_squared_error: 16462.0156\n",
            "Epoch 93/350\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 105.0716 - mean_squared_error: 32995.2930\n",
            "Epoch 93: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 105.0747 - mean_squared_error: 33013.5586 - val_loss: 69.6709 - val_mean_squared_error: 27772.2969\n",
            "Epoch 94/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 108.9843 - mean_squared_error: 33287.4023\n",
            "Epoch 94: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 108.9039 - mean_squared_error: 33212.1719 - val_loss: 52.2615 - val_mean_squared_error: 13480.5586\n",
            "Epoch 95/350\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 101.6119 - mean_squared_error: 26913.0098\n",
            "Epoch 95: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 101.6026 - mean_squared_error: 26900.3242 - val_loss: 45.5187 - val_mean_squared_error: 12340.6885\n",
            "Epoch 96/350\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 97.7268 - mean_squared_error: 23883.2715\n",
            "Epoch 96: val_loss did not improve from 44.58733\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 97.7535 - mean_squared_error: 23906.0547 - val_loss: 51.8341 - val_mean_squared_error: 14910.7930\n"
          ]
        }
      ],
      "source": [
        "# --- Training ---\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=350,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stop, checkpoint_cb],\n",
        "                    verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "o1RNayMCLDjK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "o1RNayMCLDjK",
        "outputId": "786ef788-222a-4411-8770-b7570fb78fdd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbJ9JREFUeJzt3Qd4U2X7BvA73XvTJXvvIUtEGYJMB8PFRlRkiYATFQT9FD5cKKI4ENQPBPGPyhAFUUHZQ/aQPYQyS/du/tfzniYkUGgLac5pc/+uK6ZJTpPTpHLuPu/zvsdkNpvNICIiInJhbnrvABEREZHeGIiIiIjI5TEQERERkctjICIiIiKXx0BERERELo+BiIiIiFweAxERERG5PAYiIiIicnkMREREROTyGIiISqiBAweiYsWKN/S9EyZMgMlkcvg+lUb5vVfyvsv7X5DZs2er7z169KjD9keeS55TnpuIHIeBiMjB5GBVmMsff/yh966WKmfPnoWHhwf69u17zW2SkpLg6+uLHj16wOjmzp2LqVOnwkgkBAYEBOi9G0TFwqN4npbIdX399dd2t7/66iusWLHiqvtr1ap1U6/z2WefITc394a+95VXXsGLL76I0iQyMhJ33303fvzxR6SmpsLPz++qbRYuXIj09PTrhqbC2L9/P9zc3Io9EO3atQujRo2yu79ChQpIS0uDp6dnsb4+kathICJysCsPtuvXr1eBqKCD8LUO4tdyMwdEqaTIpbTp06cPfv75ZyxatAiPPPJIviEjODgYXbt2vanX8fb2hl6kuujj46Pb6xOVVhwyI9JBmzZtULduXWzZsgWtWrVSQeill15Sj0mFQw7YsbGx6sBbpUoVvP7668jJybluD5Glt+Ttt9/Gp59+qr5Pvr9p06bYtGlTgX0xcnvEiBH44Ycf1L7J99apU0cFjCvJcF+TJk3UgVle55NPPilUX5I8vwy5SPi7Uq9evRAdHW39OTdv3oyOHTsiIiJCDXNVqlQJgwYNuu7zd+/eHf7+/ir45DektnLlSjzwwAPqZ/vzzz/x4IMPonz58up2uXLlMHr0aFV9KUh+PUS7d+/GXXfdpfa1bNmy+M9//pNvBa8wn6/8fixduhTHjh2zDrFaPutr9RD99ttvuPPOO9XPHxISgvvvvx979+6128byGR08eFDtv2wnAfHRRx/N9zO5UQsWLEDjxo3VeyGfn/wx8O+//9ptExcXp15X3it5H2JiYtQ+2/Zb3cjvANGNKn1/IhKVEBcuXEDnzp1VJUMOGFFRUep+OdBJaBgzZoy6lgPd+PHjkZiYiLfeeqvA55UwIL0yTz75pDr4TZkyRfXMHD58uMCq0l9//aWGlYYNG4bAwEB88MEH6NmzJ44fP47w8HC1zd9//41OnTqpA9jEiRPVgfy1115DmTJlCty3hx9+GNOnT1cHewkjFnIwXrx4sTpIu7u7q/DSoUMH9ZwytCcHbjlQyr5dj4QBOah+9913uHjxIsLCwqyPzZ8/X+2rVJEsB2153aFDh6qfbePGjZg2bRpOnjypHisKObi3bdsW2dnZan9lPySUykH8SoX5fF9++WUkJCSofXnvvffUfdfr3fn111/V71LlypVV6JFQJz9Ly5YtsXXr1qua7x966CEVLiZNmqQe//zzz9WQ43//+1/cLPn5JOhIEJfnP3PmDN5//32sWbNG/e7IZynk90pC5FNPPaX2Tz5zqaTK75rl9o38DhDdMDMRFavhw4ebr/xfrXXr1uq+GTNmXLV9amrqVfc9+eSTZj8/P3N6err1vgEDBpgrVKhgvX3kyBH1nOHh4eaLFy9a7//xxx/V/YsXL7be9+qrr161T3Lby8vLfPDgQet927dvV/dPmzbNet+9996r9uXff/+13nfgwAGzh4fHVc95pdzcXPMtt9xi7tmzp9393377rfre1atXq9vff/+9ur1p0yZzUS1dulR97yeffGJ3/2233aZeOycn55rv86RJk8wmk8l87Nix675X8r7L+28xatQotc2GDRus9509e9YcHBys7pfPpqifb9euXe0+3ys/51mzZlnva9iwoTkyMtJ84cIFu8/Ozc3N3L9//6t+lkGDBtk9Z/fu3dXvTUHkZ/b397/m45mZmWo/6tata05LS7Pev2TJEvW648ePV7fj4+PV7bfeeuuaz3UzvwNEN4JDZkQ6kWEC+Uv6SrZVBan0nD9/Xg2FSDVj3759harChIaGWm/L9wqpEBWkffv2agjHon79+ggKCrJ+r1RYpBrRrVs3NeRjUbVqVVWhKIhUrKQy9NNPPyE5OdmuenPLLbfgjjvuULctVYQlS5YgKysLRWGpKtgOmx05ckT1csmwnKUZ2vZ9TklJUe/z7bffLslHVTKKQn6e2267Dc2aNbPeJ/tgqUY58vO90unTp7Ft2zZVXbOtiMlnJ03msm9XGjJkiN1teX2pWEqV6mbIEJdUdqTCaNvnJEOENWvWVJVBy3vg5eWlhl7j4+Pzfa6b+R0guhEMREQ6kQAgB4UryTCC9MJIb4eEETmwWhqyZRilINITY8sSjq514Lne91q+3/K9crCT4RgJQFfK775rBTZ5Dml8FhKM5KAtQcnSg9S6dWs1pCJDctI/IsNgs2bNQkZGRoHPL83i8hrSI2TpW7GEI9uAIkMzlhAhw1HyPsvrFvZ9tiW9PtWqVbvq/ho1ajj8883vta/1WjKTUQKXBD5H/Y7c6L5IILI8Ln8MyPDcsmXL1FCx9NHJ0K4MPVrczO8A0Y1gICLSSX79JZcuXVIHgu3bt6u+HOmrkb4KS29HYabZSw9OfrRRseL73sKSSor0iHz77bfqtvyMEpAkxFhIMJI+oHXr1qlGbAk20kwrjbq2laVrkYAh79U333yjbst17dq10bBhQ2ulS6onUrF44YUXVCO5vM+WRuUbXc6gII74fB3BGZ9zQWQ5gX/++Uf1GUk1ady4cSrAWapzN/s7QFRUDEREBiJDCDJ0IQfmp59+Gvfcc48axrIdAtOTNN7KwUtmKV0pv/uuRZp6ZfaaDNHIcJkEJAlKV5L73njjDTUUM2fOHFVdmTdvXoHP37x5czX0J5UhCR/yfbbVoZ07d6qD8TvvvKMCkVQf5H22HQYsClkb6MCBA/muV3Sjn29hVxKX187vtYQMwUl1RZq8neF6+yL3WR63kM/omWeewfLly9WaS5mZmeozccTvAFFRMRARGYjlL3fbv9TlIPHRRx/BKPsnB3CpqJw6dcouDMnwR2FJNUiGPr788ksVjCQg2ZKhmyurFZbqTmGHTCQASbXh1VdfVeGid+/edj+HsH0N+VpmQ92ILl26qB4lmalmce7cOXUAv9HPV0JMYYbQZLafvDfyXkoFykIChgQN2TdnkaUYJDTPmDHD7nOS3w1ZAsCy/pP0S8kCmVeGI5nZaPk+R/wOEBUFp90TGYg09Uq1YMCAARg5cqQ6kMsK184cyiiITOuWA61M6ZYp6zL89OGHH6q1i6S5tzBuvfVW1XMk08vl4GY7XCbk4C4hQXpt5EApzceyMrf03BT2AC/DZjIsJev+yL7aTj2XfhZ53meffVYNxcjz/t///d8N99A8//zz6nOS5Qik8mOZdi8VkR07dtzQ5ytDQ1I9k+n5MoVd+pzuvffefF9fputLU3uLFi3w2GOPWafdS5+SfF6OJA3OssbSlaQXS5qpZfhPJgvI0KA0sVum3cv7L+s8CanOtWvXTgVhGcqUvq/vv/9ebWtZUNMRvwNERXJDc9OI6Kan3depUyff7desWaOmiPv6+ppjY2PNzz//vPmXX35Rz/H7778XOO0+v6nMcr9MuS5o2r3s65WunGIuVq5caW7UqJGapl+lShXz559/bn7mmWfMPj4+5sJ6+eWX1WtWrVr1qse2bt1q7tWrl7l8+fJmb29vNZX7nnvuMW/evNlcFE2bNlWv8dFHH1312J49e8zt27c3BwQEmCMiIsxPPPGEdZkB2ynthZl2L3bs2KE+V3kPZHr/66+/bp45c+ZV0+4L+/kmJyebe/fubQ4JCVGPWT7r/Kbdi19//dXcsmVL9bxBQUFqeQT5GW1ZfpZz587Z3S/PdeV+5kd+Ztkuv4v8HljMnz9f/X7IZxcWFmbu06eP+eTJk9bHz58/r37Xatasqabxy/IEzZs3V8svOPp3gKiwTPKfokUoIqKryVR86e/Ir5eGiMjo2ENEREV25ektJATJ1Hk55QQRUUnEChERFZk08soaPnKqCFlb5uOPP1a9QNLEnN96PERERsemaiIqMmkelrV9ZCE9WWRPmnnffPNNhiEiKrFYISIiIiKXxx4iIiIicnkMREREROTy2ENUCHJ+IVmVV1ZRLexy+kRERKQv6QqSRT3ltDxubtevATEQFYKEoXLlyum9G0RERHQDTpw4gbJly153GwaiQpDKkOUNlWXjiYiIyPjkBNJS0LAcx6+HgagQLMNkEoYYiIiIiEqWwrS7sKmaiIiIXB4DEREREbk8BiIiIiJyeewhIiIil5OTk4OsrCy9d4McwMvLq8Ap9YXBQERERC61Lo2cg+/SpUt67wo5iIShSpUqqWB0MxiIiIjIZVjCUGRkJPz8/LjYbilZOPn06dMoX778TX2eDEREROQyw2SWMBQeHq737pCDlClTRoWi7OxseHp63vDzsKmaiIhcgqVnSCpDVHp45Q2VSeC9GQxERETkUjhMVrqYHPR56hqIJk2ahKZNm6oltaWE2a1bN+zfv99um/T0dAwfPlyVNwMCAtCzZ0+cOXPGbpvjx4+ja9euKvXL8zz33HOqdGbrjz/+wK233gpvb29UrVoVs2fPdsrPSERERManayBatWqVCjvr16/HihUrVDmzQ4cOSElJsW4zevRoLF68GAsWLFDbyzhhjx49rI9LiUzCUGZmJtauXYsvv/xShZ3x48dbtzly5Ijapm3btti2bRtGjRqFxx9/HL/88ovTf2YiIiIjqFixIqZOnar3bhiH2UDOnj1rll1atWqVun3p0iWzp6enecGCBdZt9u7dq7ZZt26duv3TTz+Z3dzczHFxcdZtPv74Y3NQUJA5IyND3X7++efNderUsXuthx9+2NyxY8dC7VdCQoJ6TbkmIqKSKS0tzbxnzx51XZLI8ed6l1dfffWGj7kpKSk3tW+tW7c2P/3002ajfq5FOX4bqocoISFBXYeFhanrLVu2qKpR+/btrdvUrFlTTa1bt26dui3X9erVQ1RUlHWbjh07qjPc7t6927qN7XNYtrE8h15ycs2IS0jHsQuXK2JERES2ZEq55SIVHTnJuO19zz77rHVbyU9Xtoxcb3YWG8wvczPSWgIylNWyZUvUrVvXul6EdI+HhITYbSvhRx6zbGMbhiyPWx673jYSmtLS0q7al4yMDPWY7aU4nElMx22TVuLud1cXy/MTEVHJFx0dbb0EBwerJmLL7X379qk+3GXLlqFx48aqT/avv/7CoUOHcP/996tjnfTfSr/ur7/+et0hM5PJhM8//xzdu3dXQalatWpYtGjRTe37//3f/6FOnTpqv+T13nnnHbvHP/roI/U6Pj4+al8feOAB62PfffedKnj4+vqqPmIpbNi21DiaYdYhkl6iXbt2qQ9Sb9LsPXHixGJ/HV9Pd3WdmZOL7JxceLgbJp8SEbkEqaikZd3cdO2bOQY4aobUiy++iLfffhuVK1dGaGgoTpw4gS5duuCNN95QYeSrr77CvffeqyYuySjLtUycOBFTpkzBW2+9hWnTpqFPnz44duyYdeSmKGSU56GHHsKECRPw8MMPqz7fYcOGqXAzcOBAbN68GSNHjsTXX3+N22+/HRcvXsSff/6pvlcqX7169VL7IgEtKSlJPaaNIJbiQDRixAgsWbIEq1evRtmyZa33S/qVZmlZSMu2SiSzzOQxyzYbN260ez7LLDTbba6cmSa3pewoyfNKY8eOxZgxY6y3pUJUrlw5OJqvlxaIRHp2LgIYiIiInErCUO3x+kyw2fNaR/h5OeYw/Nprr+Huu++23pYA06BBA+vt119/Hd9//72q+Mgx91oGDhyogoh488038cEHH6hjbKdOnYq8T++++y7atWuHcePGqdvVq1fHnj17VNiS15EZ4v7+/rjnnntUlatChQpo1KiRNRDJ0J9MopL7hVSLipOuR2BJevLByIf022+/qXOR2JLyn6w6uXLlSut9km7lTWzRooW6Ldc7d+7E2bNnrdvIjDUJO7Vr17ZuY/sclm0sz3ElSdPy/baX4uDt4QbLHwepmYUb8yUiIrpSkyZN7G4nJyer3qJatWqpgoIMm+3du1cdP6+nfv361q8lrMjxz/b4WhTyetIGY0tuHzhwQM0QlwAnYUeqWv369cOcOXOQmpqqtpMwJ2FKQtCDDz6Izz77DPHx8ShOHnoPk82dOxc//vijSoeWnh8ZI5XKjVw/9thjqlojaVc+mKeeekoFmdtuu01tK9P0JfjImymlNXmOV155RT23BBsxZMgQfPjhh3j++ecxaNAgFb6+/fZbLF26VM8fX5VKpWSampmD9MxcXfeFiMgVyb/BUqnR67UdRcKLLQlD8oe/DKPJ2ntyTJX+HBl1uR7PK059Iccp6fEtDnLc37p1q1oncPny5Wq5HBle27Rpkwpxsv8yzCaPyfDdyy+/jA0bNlxVPCkVFaKPP/5YzSxr06YNYmJirJf58+dbt3nvvfdUOU0WZGzVqpUa/lq4cKH1cXd3dzXcJtcSlPr27Yv+/fur8qGFvHkSfuTNldQpTV3SOCYzzfRm+R9CrzFsIiJXJgd8GbbS41KcK2avWbNGDUtJ/41UWeTYefToUThTrVq11H5cuV8ydCbHbOHh4aGapaWgsWPHDrWPUrQQ8v5IRUn6mv7++281yUpGlEplhagwzVHSeT59+nR1uRYpuf3000/XfR4JXfKGGo0PAxERETmYzNyS4oE0UkuwkD6e4qr0nDt3Ti16bEuKG88884ya3Sb9S9JULUvdyGiNzCwTUsw4fPiwKnZII7gcx2Ufa9SooSpB0uoio0ByBgq5La8jIatUN1W7MktjdVomAxERETmGNDRLi4jM3oqIiMALL7xQbEvIzJ07V11sSQiS9hVpT5GhMLktIUlGb6RyJWRYTEKbDJPJabokxH3zzTdqmr70H8lEK1kWQPZbCh8yutO5c2cUF5Oszlhsz15KyIch/UwyvOfoBut7p/2Fnf8mYNbApmhbM9Khz01ERJfJQVdO5SRtFDL6QKX/c00swvGb87x1xh4iIiIi/TEQ6cyHQ2ZERES6YyDSma+n9hGwQkRERKQfBiKDDJmlMxARERHphoFIZ755y7bL4oxERESkDwYinbGpmoiISH8MRDrz9crrIWKFiIiISDcMRDpjDxEREZH+GIh0xlN3EBER6Y+BSGc8dQcRETmDnNNz1KhReu+GYTEQ6YxN1UREdD1ygtZOnTrl+9iff/6pTt4qZ4q/WbNnz1bnF3NVDEQ6Yw8RERFdz2OPPYYVK1bg5MmTVz02a9YsNGnSBPXr19dl30oTBiKjnLqDgYiIiPJxzz33oEyZMqqCYys5ORkLFixQgenChQvo1asXbrnlFvj5+aFevXrqzPGOdPz4cdx///0ICAhQJ0p96KGHcObMGevj27dvR9u2bREYGKgeb9y4MTZv3qweO3bsmKp0hYaGwt/fX53R/qeffoKRaKsCkv5DZuwhIiJyPrMZyErV57U9/QCTqcDNPDw80L9/fxWIXn75ZTVEJiQM5eTkqCAk4UgCyAsvvKDCyNKlS9GvXz9UqVIFzZo1u+ldzc3NtYahVatWITs7G8OHD8fDDz+MP/74Q23Tp08fNGrUCB9//DHc3d2xbds2eHp6qsdk28zMTKxevVoFoj179qjnMhIGIp35samaiEg/EobejNXntV86BXj5F2rTQYMG4a233lJhRJqjLcNlPXv2RHBwsLo8++yz1u2feuop/PLLL/j2228dEohWrlyJnTt34siRIyhXrpy676uvvlKVnk2bNqFp06aqgvTcc8+hZs2a6vFq1apZv18ek32VypWoXLkyjIZDZjpjUzURERVEQsbtt9+OL774Qt0+ePCgaqiW4TIhlaLXX39dBY6wsDBVfZFAJEHEEfbu3auCkCUMidq1a6smbHlMjBkzBo8//jjat2+PyZMn49ChQ9ZtR44cif/85z9o2bIlXn31VYc0gTsaK0Q64zpEREQ6kmErqdTo9dpFIOFHKj/Tp09X1SEZDmvdurV6TKpH77//PqZOnapCkQxLyRR7GaZylgkTJqB3795quG7ZsmUq+MybNw/du3dXQaljx47qseXLl2PSpEl455131M9jFKwQGWQdovSsXOTmmvXeHSIi1yL9ODJspcelEP1DtqSJ2c3NDXPnzlXDVTKMZuknWrNmjerx6du3Lxo0aKCGpP755x+HvU21atXCiRMn1MVC+oAuXbqkKkUW1atXx+jRo1Xo6dGjhwpuFlJdGjJkCBYuXIhnnnkGn332GYyEFSKDDJmJjOxca0AiIiKyJcNg0sQ8duxYJCYmYuDAgdbHpF/nu+++w9q1a9VMrnfffVfNALMNK4WRk5OjmqFteXt7q2EwqTxJ47RUoaSpetiwYapCJdP+09LSVP/QAw88gEqVKqklAqS3SPqGhFSrOnfurAJTfHw8fv/9dxWyjISByCBDZpZhMwYiIiK63rDZzJkz0aVLF8TGXm4Gf+WVV3D48GE1LCXT7gcPHoxu3bohISGhSM+fnJysZorZkqE56Vn68ccf1RBXq1atVKVKFoucNm2a2kZmlcnUf5kNJ0EsIiJCVYgmTpxoDVoy00yCksyCk+997733YCQms1nmHNL1SBKXDn75xZIP0tGqv7IMmdm5WPPiXbglxNfhz09EREB6erqaJSUVDB8fH713h5zwuRbl+M0eIgPgWkRERET6YiAyAJ6+g4iISF8MRAZg6RtKZYWIiIhIFwxEBsDFGYmIiPTFQGSgChF7iIiIih/nEpUuZgd9ngxEBsAeIiKi4mc50Whqqk4nc6ViYVmNW6b+3wyuQ2QAPH0HEVHxkwOmnHvr7Nmz6ras12NZ6ZlKptzcXJw7d059lh4eNxdpGIgMgENmRETOER0dra4toYhKPjc3N5QvX/6mwy0DkQH4emojl6wQEREVLzloxsTEIDIyEllZWXrvDjmAl5eXCkU3S9dAtHr1anWG3i1btuD06dP4/vvv1VLjFtdKe1OmTFHnTBEVK1bEsWPH7B6Xs+i++OKL1ts7duxQS4bLeVXKlCmjlh5//vnnYRTsISIicv7w2c32nFDpomtTdUpKijor7/Tp0/N9XEKS7eWLL75QIclysjiL1157zW47CTy2y3Z36NABFSpUUMFLAtiECRPw6aefwih8OGRGRESkK10rRHLmW7kUNNZrISeWa9u2LSpXrmx3f2Bg4FXbWsyZM0d1oEuYkrJanTp11Jl85UzAcvI7I+A6RERERPoqMdPu5ey5S5cuVWf6vdLkyZMRHh6uztArFaDs7GzrY+vWrVNn5pUwZCFnA96/fz/i4+NhBDyXGRERkb5KTFP1l19+qSpBPXr0sLt/5MiRuPXWWxEWFoa1a9di7NixathMKkAiLi5OnQHXVlRUlPWx0NDQq14rIyNDXWyH3YqTn2XIjBUiIiIiXZSYQCRDXn369IGPj4/d/WPGjLF+Xb9+fVUJevLJJ1Vjtbe39w29lnzvxIkT4Sxch4iIiEhfJWLI7M8//1RDXI8//niB2zZv3lwNmR09elTdlt4iGW6zZbl9rb4jqTIlJCRYLydOnEBx4jpERERE+ioRgWjmzJlo3LixmpFWEGmYlvUIZI0J0aJFCzW933a9iRUrVqBGjRr5DpcJqSwFBQXZXYoTp90TERG5cCBKTk5WAUYu4siRI+rr48eP2/XvLFiwIN/qkDRMT506Fdu3b8fhw4fVjLLRo0ejb9++1rDTu3dvNYwmzdi7d+/G/Pnz8f7779sNtemNs8yIiIhcuIdo8+bNahq9hSWkDBgwALNnz1Zfz5s3T53JtlevXvlWcuRxWVdImqCleVoCkW3YCQ4OxvLly9XCjFJlioiIwPjx4w0z5d5uHSIGIiIiIl2YzJI26LqkSiXBSvqJimP4bO/pRHR+/09EBHhj8yvtHf78REREriixCMfvEtFDVNqxh4iIiEhfDEQGYJ1llpWjhgeJiIjIuRiIDMCyDlFOrhmZObl67w4REZHLYSAyAMtK1SI9k4GIiIjI2RiIDMDT3Q0ebib1NWeaEREROR8DkUFwLSIiIiL9MBAZbS0inr6DiIjI6RiIDIIVIiIiIv0wEBkE1yIiIiLSDwORQXDIjIiISD8MRAbh66l9FBwyIyIicj4GIoNgDxEREZF+GIiMdvoODpkRERE5HQORwU7fwQoRERGR8zEQGez0HawQEREROR8DkUFw2j0REZF+GIgMgk3VRERE+vHQ8bUpPQHY9g2QkwEfr67qLg6ZEREROR8DkZ4yU4CfXwBM7vBtd6+6ixUiIiIi5+OQmZ68g7Rrcw4C3DLVl+whIiIicj4GIj15+QMm7SMIMqWpa1aIiIiInI+BSE8mE+AdqL70R6q6TmUPERERkdMxEOnNO1hd+Zu1QMSmaiIiIudjINJbXoXIz5yirtlDRERE5HwMRHrz0RqrfXPzKkQMRERERE7HQGSQmWY+uVqFiENmREREzsdAZJAhM++cZHWdnpWr8w4RERG5HgYigwyZeWVrFaLMnFxk5zAUERERORMDkUEqRJ7ZSda70rMZiIiIiJyJgcggPUTumdqQmWAfERERkXMxEOnNR1uHyJSRaD3jPafeExERORcDkUGGzCCByEsLRFytmoiIyIUC0erVq3HvvfciNjYWJpMJP/zwg93jAwcOVPfbXjp16mS3zcWLF9GnTx8EBQUhJCQEjz32GJKTLw8/iR07duDOO++Ej48PypUrhylTpsBwJ3jNSLJWiLgWERERkQsFopSUFDRo0ADTp0+/5jYSgE6fPm29fPPNN3aPSxjavXs3VqxYgSVLlqiQNXjwYOvjiYmJ6NChAypUqIAtW7bgrbfewoQJE/Dpp5/CSLPMkJ4IH0/t42APERERkXN5QEedO3dWl+vx9vZGdHR0vo/t3bsXP//8MzZt2oQmTZqo+6ZNm4YuXbrg7bffVpWnOXPmIDMzE1988QW8vLxQp04dbNu2De+++65dcNJ/yCwJft7ax8EeIiIiIucyfA/RH3/8gcjISNSoUQNDhw7FhQsXrI+tW7dODZNZwpBo37493NzcsGHDBus2rVq1UmHIomPHjti/fz/i4+NhnCGzy03VHDIjIiJyoQpRQWS4rEePHqhUqRIOHTqEl156SVWUJOS4u7sjLi5OhSVbHh4eCAsLU48JuZbvtxUVFWV9LDQ09KrXzcjIUBfbYbfinmWGrFT4e5rVlxwyIyIici5DB6JHHnnE+nW9evVQv359VKlSRVWN2rVrV2yvO2nSJEycOBFOHTIDEOKerq5ZISIiInIuww+Z2apcuTIiIiJw8OBBdVt6i86ePWu3TXZ2tpp5Zuk7kuszZ87YbWO5fa3epLFjxyIhIcF6OXHiRDH9RLIioyfg4au+DHXTAhF7iIiIiJyrRAWikydPqh6imJgYdbtFixa4dOmSmj1m8dtvvyE3NxfNmze3biMzz7KysqzbyIw06UnKb7jM0sgt0/htL86oEoW4p6lrDpkRERG5UCCS9YJkxpdcxJEjR9TXx48fV48999xzWL9+PY4ePYqVK1fi/vvvR9WqVVVTtKhVq5bqM3riiSewceNGrFmzBiNGjFBDbTLDTPTu3Vs1VMv6RDI9f/78+Xj//fcxZswYGEbe1PtAU14gYoWIiIjIdQLR5s2b0ahRI3URElLk6/Hjx6umaVlQ8b777kP16tVVoGncuDH+/PNPVcGxkGn1NWvWVD1FMt3+jjvusFtjKDg4GMuXL1dhS77/mWeeUc9viCn3V8w0C8oLRFypmoiIyIWaqtu0aQOzWZtZlZ9ffvmlwOeQGWVz58697jbSjC1ByrDyhswCoAUi9hARERE5V4nqISq18obMApCqrjlkRkRE5FwMREbgra1F5G9OUddsqiYiInIuBiIDDZn55rJCREREpAcGIgMNmfnkahUi9hARERE5FwORgSpE3jnJ6poVIiIiIudiIDLQtHvvHPYQERER6YGByEBDZp5ZWoUoPStX5x0iIiJyLQxEBhoy88jmkBkREZEeGIgMNO3eIytJXadmZuu8Q0RERK6FgchAQ2ZumUnWIbPc3Guv4E1ERESOxUBkoCEzU4YEIi0IZWSzj4iIiMhZGIgMNMvMZM6BLzLU1+wjIiIich4GIiPw8gdM2kcR7pGurhmIiIiInIeByAhMJuuwWbhHprrmWkRERETOw0BksJlmEXkVIp6+g4iIyHkYiIwir0IU6sEeIiIiImdjIDLY1PtQ9zR1zSEzIiIi52EgMthMsxA3LRClMhARERE5DQORwYbMgtzYQ0RERORsDEQGGzILNqWqa/YQEREROQ8DkcEqRAFgDxEREZGzMRAZrIcoAKwQERERORsDkVH4aOsQ+ecFIvYQEREROQ8DkcGGzPxy8ypEHDIjIiJyGgYigw2Z+eamqGsOmRERETkPA5HBZpl5MxARERE5HQORwYbMvHO0QMQeIiIiIudhIDLYkJlXdrK65krVREREzsNAZLBA5JGTBnfk4GJKpt57RERE5DIYiAzWQ2RZnPHYBW22GRERERU/BiKjcPcEPHzVl4GmVCSkZSGeVSIiIiKnYCAyYGN1RX+tf+joBa3BmoiIiEpxIFq9ejXuvfdexMbGwmQy4YcffrA+lpWVhRdeeAH16tWDv7+/2qZ///44deqU3XNUrFhRfa/tZfLkyXbb7NixA3feeSd8fHxQrlw5TJkyBUYeNqsalKuuOWxGRETkAoEoJSUFDRo0wPTp0696LDU1FVu3bsW4cePU9cKFC7F//37cd999V2372muv4fTp09bLU089ZX0sMTERHTp0QIUKFbBlyxa89dZbmDBhAj799FMYtbG6YgArRERERM7kAR117txZXfITHByMFStW2N334YcfolmzZjh+/DjKly9vvT8wMBDR0dH5Ps+cOXOQmZmJL774Al5eXqhTpw62bduGd999F4MHD4YRh8zK+mera1aIiIiInKNE9RAlJCSoIbGQkBC7+2WILDw8HI0aNVIVoOxsLVCIdevWoVWrVioMWXTs2FFVm+Lj42HEIbMYb62Z+sh5VoiIiIhKfYWoKNLT01VPUa9evRAUdHmK+siRI3HrrbciLCwMa9euxdixY9WwmVSARFxcHCpVqmT3XFFRUdbHQkNDr3qtjIwMdbEddnPmkFmElxaIjnHIjIiIyClKRCCSBuuHHnoIZrMZH3/8sd1jY8aMsX5dv359VQl68sknMWnSJHh7e9/Q68n3Tpw4EU6XF4hC3dPUdXxqFhJSsxDs5+n8fSEiInIhbiUlDB07dkz1FNlWh/LTvHlzNWR29OhRdVt6i86cOWO3jeX2tfqOpMokw3OWy4kTJ+DMITOvrGSUCdTC3LGLrBIRERG5dCCyhKEDBw7g119/VX1CBZGGaTc3N0RGRqrbLVq0UNP75bksJFjVqFEj3+EyIZUlCV62F2c2VSMjCZXC/dWXR9lYTUREVLoDUXJysgowchFHjhxRX8ssMgkwDzzwADZv3qxmiuXk5KieH7nIrDFLw/TUqVOxfft2HD58WG03evRo9O3b1xp2evfurYbRHnvsMezevRvz58/H+++/bzfUZhh5Q2bISESFcD/15VE2VhMREZXuHiIJO23btrXetoSUAQMGqLWCFi1apG43bNjQ7vt+//13tGnTRlVy5s2bp7aVJmhpnpZAZBt2ZPr+8uXLMXz4cDRu3BgREREYP3688abc257PLD0RFWMsFSIGIiIiolIdiCTUSKP0tVzvMSGzy9avX1/g60iz9Z9//gnDsxkys1SIuBYRERGRi/cQuRzvYO06IwEV83qIOPWeiIio+DEQGXHIzKZCdD45E0nplxvCiYiIyICBSJqdpRHacKs+l0SWIbP0RAR6eyAiQFtdm8NmREREBgtEo0aNwsyZM61hqHXr1qqXR84i/8cffxTHProOyywzcw6QlYoK1qn3HDYjIiIyVCD67rvv1BnqxeLFi9VU+X379qnZXS+//HJx7KPr8PIHTHkfCRuriYiIjBuIzp8/b13h+aeffsKDDz6I6tWrY9CgQdi5c2dx7KPrMJnshs0sjdVci4iIiMhggUhOjLpnzx41XPbzzz/j7rvvVvenpqbC3d29OPbRRWeaJaJihGWmGStEREREhlqH6NFHH1Wn04iJiYHJZEL79u3V/Rs2bEDNmjWLYx9di3UtIqkQVVVfsoeIiIjIYIFIVoWuW7euOuGpDJdZzigv1aEXX3yxOPbRtdisVl0hb7Xqs0kZSMnIhr+3rutoEhERlVo3dISVc4zZunTpkjrdBjnyfGZJCPbzRKifJ+JTs9SwWe1YJ51kloiIyMUUuYfov//9rzpBqoUMn8lZ6MuWLYsdO3Y4ev9ceshMWKbec8VqIiIiAwWiGTNmqDWHxIoVK9Rl2bJl6NSpE5599tni2EeXHTITFS1nvWdjNRERkXGGzOLi4qyBaMmSJapC1KFDB1SsWBHNmzcvjn10LTYneBWXZ5qxQkRERGSYClFoaKhqqBYy7d4yy0zOTC9T8clRPUQJ6sqyFtERrkVERERknApRjx490Lt3b1SrVg0XLlxA586d1f1///03qlbVponTTfAJthsy42rVREREBgxE7733nhoekyrRlClTEBAQoO4/ffo0hg0bVhz76Fp8QrTrU38DyedQMVwLSHGJ6UjLzIGvFxe/JCIicjSTWca66LoSExMRHByMhIQEBAUV89T31IvAJ62AhBNAdH2YByxGg/9uQGJ6Nn4Z1Qo1ovN6jIiIiMhhx+8i9xCJQ4cO4amnnlL9Q3IZOXIkDh8+fCNPRVfyCwP6/QD4RQBxO2D6phdqhGtVoX/OaI3WREREpHOF6JdffsF9992Hhg0bomXLluq+NWvWYPv27Vi8eLH13GaliVMrRBantwOz71HrEe32vw3dLgxDFjxUT1GjciFoVD4UNaMD1erVfl7u8PPyUMNpvp7u8HQ3qdOq2MrJNSMxLQuJ6VlISs9GZk4usrJzkZ1rVl/n5mq/BpZvM8EEH093hPrL4pBeCPHzhLeHu9ouJTMbCfJcadlIy8qGl7s7fL3c1Pby+sG+nvBwv6GsTUREpMvxu8iBqFGjRujYsSMmT55sd7+ctmP58uXYunUrShtdApE4tg74ujuQnYY/PO7Ahyl3IQfuyIK7us65RoFPQo2Xuxu8PNzg6e6G9KwcpGbmwISrP2ozTFd9fa1fCG8PN2RJeLpiA/kuN+Sqa3mNbP8YfDu6K0L9vW7mpyciIjJuIPLx8cHOnTvVLDNb//zzD+rXr4/09HSUNroFInFgBfDNI0BuNkqKNLMX1t6zEu2a1td7V4iIyIUlFuH4XeRZZmXKlMG2bduuCkRyX2RkZNH3lq6v2t3AQ18DqyYDGclaMLJeLq/7ZLa9NpvVtfa1VIxkCC3v2qYiZFcLsuZi8+XbeeNn6rnM2lpT1uey/T6TW962JuSkXICvKRMXDm0FGIiIiKiEKHIgeuKJJzB48GDVRH377bdbe4jkHGdjxowpjn2kml20y3VYAop955BjaFGncM582AWx59fg0pnjxbAnREREBglE48aNQ2BgIN555x2MHTtW3RcbG4sJEybg6aefLo59pBLEN6wscB7Iij9prSgREREZXZGnAskBbvTo0Th58qQak5OLfC2Vo7Vr1xbPXlKJERRZXl2HZJ/Hyfg0vXeHiIioUG5qbrRUiuQiDhw4gDvvvPNmno5KAfeQWHUdZbqIHSe187EREREZHReLIccKukVdRZvisfNfBiIiIioZGIjIsQJjrBWinf9e0ntviIiICoWBiBwrSBsyK2NKxN6TF1RjNRERUamZZbZo0aLrPn7kyBFH7A+VdH7hMLt7wZSTCd/0czh+MRUVwv313isiIiLHBKJu3boVuA2nWJMs0GgKjAYuHUeUKV41VjMQERFRqRkyy83NLfCSk3N55WRyYYHasFm06SJ2sbGaiIhKAF17iFavXo17771XLewo1aUffvjB7nHpPxk/fjxiYmLg6+uL9u3bq+n9ti5evIg+ffqoc5SEhITgscceQ3Jyst02O3bsUEsCyHnYypUrhylTpjjl53NZQTHWmWacek9ERCWBroEoJSUFDRo0wPTp0/N9XILLBx98gBkzZmDDhg3w9/dHx44d7U4gK2Fo9+7dWLFiBZYsWaJClpxaxPbEbh06dECFChWwZcsWvPXWW2pV7U8//dQpP6MrV4ii8ipEublsrCYiolJ26g5H6ty5s7rkR6pDU6dOxSuvvIL7779f3ffVV18hKipKVZIeeeQR7N27Fz///DM2bdqEJk2aqG2mTZuGLl264O2331aVpzlz5iAzMxNffPEFvLy8UKdOHXUi2nfffdcuOJHjK0SxbvFIysjGsYupqBTBPiIiIjIuw067l1lrcXFxapjMIjg4GM2bN8e6devUbbmWYTJLGBKyvZubm6ooWbZp1aqVCkMWUmXav38/4uPjnfozudpaRJW9teGyHSe5HhERERmbYQORhCEhFSFbctvymFxHRkbaPe7h4YGwsDC7bfJ7DtvXuFJGRoYaarO9UNHXIooxaYGTjdVERFRqAtHGjRuvO4tMQsS3336L0mDSpEmqGmW5SCM2Fb1CFJx9XgY/2VhNRESlJxC1aNECFy5csN6WWV2HDx+23r506RJ69erlsB2Ljo5W12fOnLG7X25bHpPrs2fP2j2enZ2tZp7ZbpPfc9i+xpXGjh2LhIQE6+XEiRMO+7lcKRC552YiBMnYfSqRjdVERFQ6AtGVp2DI75QMjjxNQ6VKlVRgWblypfU+GbqS3iAJZ0KuJYjJ7DGL3377Ta2JJL1Glm1k5llWVpZ1G5mRVqNGDYSGhub72t7e3irw2V6oCDx91IrVorznJSRnZOPIhRS994qIiMg5PURFXala1guSGV9ysTRSy9fHjx9XzzVq1Cj85z//UacN2blzJ/r3769mjllWza5VqxY6deqEJ554Qg3prVmzBiNGjFAz0GQ70bt3b9VQLesTyfT8+fPn4/3338eYMWMc+aPTNabeNwvPUNc7OWxGREQGpuu0+82bN6Nt27bW25aQMmDAAMyePRvPP/+8WqtIpsdLJeiOO+5Q0+xlgUULmVYvIahdu3ZqdlnPnj3V2kUW0gO0fPlyDB8+HI0bN0ZERIRa7JFT7p0w9f7MTtQPSgXigJ3/JqBbo1v03isiIqKbD0R79uyxzsyS4bF9+/ZZV4U+f14aaIumTZs21x1mkyrRa6+9pi7XIjPK5s6de93XqV+/Pv78888i7x/dfB9RVZ8kdc0KERERlZpAJFUY2wBzzz33WIOL3M+Tu9KVU+9j3bWp93vjuHQBERGVgkAk/T1ERa0Q+aVrswCT0rORk2uGuxtDMxERleBAJOcCK8iuXbtudn+olFWIPFIvL34ps82CfT113CkiIqJimmWWlJSkTpTarFkzdaJWItsKkVvSaXh5uFkDERERUakKRLK2j8wGi4mJUSdSveuuu7B+/XrH7h2V+AoRUi8gwjtXfZmUfnktKCIiohLbVC0zzGQ6/MyZM9UiiQ899JA6ZYecfb527drFt5dU8viGAu7eQE4GKngl4lRKkOojIiIiKtEVonvvvVet7rxjxw5MnToVp06dwrRp04p376jkkhmHshaRWq1am3LPChEREZX4CtGyZcswcuRIDB06FNWqVSvevaLSs1p1/FGUdb8EoBwrREREVPIrRH/99ZdqoJbVnuU8YR9++OENLcZILiSvQhRtuqiuGYiIiKjEB6LbbrsNn332GU6fPo0nn3wS8+bNU+cLkxOpyslSJSwR5ddYHQltcUYGIiIiKjWzzPz9/TFo0CBVMZITrj7zzDOYPHkyIiMjcd999xXPXlKJPsFreO4FdZ2cwR4iIiIqhesQSZP1lClTcPLkSXzzzTeO2ysqVUNmoTna0CorREREVGoXZhTu7u7o1q0bFi1a5Iino1JWIQrMOqeuGYiIiKjEzzKTYbKCyMldZY0iItsKkX+mBCIzp90TEVHJD0SyIKOcz6xRo0Z2Z7wnuqaAaHXlnpuFMCQhKT1c7z0iIiK6uUAk6w9Jn5Cc9f7RRx9F3759ERYWVthvJ1fk4QX4lwFSzqmp90npZfXeIyIiopvrIZo+fbqacv/8889j8eLFKFeunDp1xy+//MKKERV4klcViDjLjIiISkNTtbe3N3r16qXWHdqzZw/q1KmDYcOGoWLFikhOTi6+vaQSvxZRtCmeTdVERFT6Zpm5ubmpJmqpDuXk5Dh2r6jUVYiiTBeRnJ7NaiIREZX8QCRntpc+orvvvhvVq1dXCzPKKTyOHz+OgICA4ttLKvkVIsQjO9eM9KxcvfeIiIjoxpuqZWhMTtchvUMyBV+CUURERGG/nVy9h8jNcj6zLPh6ueu8U0RERDcYiGbMmIHy5cujcuXKWLVqlbrkZ+HChYV9SnKhtYhi3fLOZ5aRjUidd4mIiOiGA1H//v1VzxDRjaxWHcUTvBIRUWlZmJGoyPy0taoCkMLVqomIqHSfy4zomrwD1ZUbzPBDBitERERkSAxEVLw8/QCT1kQdgDQ19Z6IiMhoGIioeEnfWV6VKNCUikQOmRERkQExEFHx8w6yVog4ZEZEREbEQETFL69CFGBiICIiImNiICLnBSLpIeIJXomIyIAYiMhpgSjIlMoKERERGRIDETm1QsRARERERmT4QFSxYkW1QvaVl+HDh6vH27Rpc9VjQ4YMsXsOOfls165d4efnh8jISDz33HPIzuaBWZdAlMH3nYiISvBK1XrZtGkTcnJyrLd37dqFu+++Gw8++KD1vieeeAKvvfaa9bYEHwv5XglD0dHRWLt2LU6fPq1OQ+Lp6Yk333zTiT+JC7NrqmYPERERGY/hA1GZMmXsbk+ePBlVqlRB69at7QKQBJ78LF++HHv27MGvv/6KqKgoNGzYEK+//jpeeOEFTJgwAV5eXsX+M7g8n2B1FcghMyIiMijDD5nZyszMxP/+9z8MGjTI7kSzc+bMQUREBOrWrYuxY8ciNTXV+ti6detQr149FYYsOnbsiMTEROzevdvpP4NLYoWIiIgMzvAVIls//PADLl26hIEDB1rv6927NypUqIDY2Fjs2LFDVX7279+PhQsXqsfj4uLswpCw3JbH8pORkaEuFhKeyDE9ROlZucjKyYWne4nK4kREVMqVqEA0c+ZMdO7cWYUfi8GDB1u/lkpQTEwM2rVrh0OHDqmhtRsxadIkTJw40SH7TPYVIiHnMwv151AlEREZR4n5M/3YsWOqD+jxxx+/7nbNmzdX1wcPHlTX0lt05swZu20st6/VdyTDbgkJCdbLiRMnHPRTuHYgCs4LROwjIiIioykxgWjWrFlqyrzMGLuebdu2qWupFIkWLVpg586dOHv2rHWbFStWICgoCLVr1873Oby9vdXjthe6+XOZBeYFIp7glYiIjKZEDJnl5uaqQDRgwAB4eFzeZRkWmzt3Lrp06YLw8HDVQzR69Gi0atUK9evXV9t06NBBBZ9+/fphypQpqm/olVdeUesYSfAh5/YQiWSuRURERAZTIgKRDJXJ4ooyu8yWTJmXx6ZOnYqUlBSUK1cOPXv2VIHHwt3dHUuWLMHQoUNVtcjf318FK9t1i8g5FSJ/yOw/M4fMiIjIcEpEIJIqj9lsvup+CUCrVq0q8PtlFtpPP/1UTHtHha0QuSMXPsjk1HsiIjKcEtNDRCWYlz8Ak3VxRg6ZERGR0TAQUfGTRTTzhs20xRkZiIiIyFgYiMjpjdWcZUZEREbDQERODUSBplRWiIiIyHAYiMi5gUh6iBiIiIjIYBiIyOlDZpxlRkRERsNARM7hw6ZqIiIyLgYicnqFiNPuiYjIaBiIyOnnM2OFiIiIjIaBiJxcIUrltHsiIjIcBiJy8rR7bcgsN/fqU7EQERHphYGInN5DJKelS83K0XuPiIiIrBiIyDlsKkSCU++JiMhIGIjIqYEo2M0SiNhYTURExsFARM7hHayuAk3p6poVIiIiMhIGInJqhcgfrBAREZHxMBCRcwORORWAmYGIiIgMhYGInBqIPJANb2QxEBERkaEwEJFzeAVYv1RnvM9gDxERERkHAxE5h5sb4JW3FpEplRUiIiIyFAYi0mVxRgYiIiIyEgYich6fyyd45fnMiIjISBiISJcKUTIrREREZCAMROQ8HDIjIiKDYiAi5wciUxqSOMuMiIgMhIGInH+CV1aIiIjIYBiIyHm8LU3VqewhIiIiQ2EgIudhDxERERkUAxHp0kOUmZOL9KwcvfeIiIhIYSAipw+ZSYVIJGewSkRERMbAQEROrxCFuKWraw6bERGRUTAQkdMrREFuWoUoiatVExGRQRg6EE2YMAEmk8nuUrNmTevj6enpGD58OMLDwxEQEICePXvizJkzds9x/PhxdO3aFX5+foiMjMRzzz2H7GxWJvTuIRKsEBERkVF4wODq1KmDX3/91Xrbw+PyLo8ePRpLly7FggULEBwcjBEjRqBHjx5Ys2aNejwnJ0eFoejoaKxduxanT59G//794enpiTfffFOXn8elWQKRmYGIiIiMxfCBSAKQBJorJSQkYObMmZg7dy7uuusudd+sWbNQq1YtrF+/HrfddhuWL1+OPXv2qEAVFRWFhg0b4vXXX8cLL7ygqk9eXl46/EQuLC8Q+ZlT1TWHzIiIyCgMPWQmDhw4gNjYWFSuXBl9+vRRQ2Biy5YtyMrKQvv27a3bynBa+fLlsW7dOnVbruvVq6fCkEXHjh2RmJiI3bt36/DTuLi8QOSJLHghixUiIiIyDENXiJo3b47Zs2ejRo0aarhr4sSJuPPOO7Fr1y7ExcWpCk9ISIjd90j4kceEXNuGIcvjlseuJSMjQ10sJECR4wKR4OKMRERkJIYORJ07d7Z+Xb9+fRWQKlSogG+//Ra+vr7F9rqTJk1S4YsczM0d8AoAMpNVY3UyT/BKREQGYfghM1tSDapevToOHjyo+ooyMzNx6dIlu21klpml50iur5x1ZrmdX1+SxdixY1WPkuVy4sSJYvl5XBJP8EpERAZUogJRcnIyDh06hJiYGDRu3FjNFlu5cqX18f3796seoxYtWqjbcr1z506cPXvWus2KFSsQFBSE2rVrX/N1vL291Ta2F3IQns+MiIgMyNBDZs8++yzuvfdeNUx26tQpvPrqq3B3d0evXr3UNPvHHnsMY8aMQVhYmAotTz31lApBMsNMdOjQQQWffv36YcqUKapv6JVXXlFrF0noIT3XIkrFoXPJeu8NERGR8QPRyZMnVfi5cOECypQpgzvuuENNqZevxXvvvQc3Nze1IKM0QcsMso8++sj6/RKelixZgqFDh6qg5O/vjwEDBuC1117T8adycTZDZvvPJKmp94E+nnrvFRERuTiT2Ww2670TRiezzKQiJf1EHD67SfP7AnsX4x3PwZiW1AZfP9YMd1bTAi4REZFex+8S1UNEped8ZtVDtBy+5Vi8zjtERETEQEQ6BaKKAbnqmoGIiIiMgIGIdOkhivXVZphtO34JObkctSUiIn0xEJEugSjUPR3+Xu5IysjGgbNJeu8VERG5OAYi0iUQuWUmo2F57bQrHDYjIiK9MRCRPuczy0hE4/Kh6ksGIiIi0hsDEenSVC2B6NYKWiDaykBEREQ6YyAinSpESWiUVyE6eiEV55Mz9N0vIiJyaQxE5Fw+lgpREoJ9PVE9KkDdZJWIiIj0xEBEulWIRGPLsNnxS3ruFRERuTgGItInEGWnA9mZuDVv2IwVIiIi0hMDETmXV14gEpnJ1grR9pOXkJmtrV5NRETkbAxE5FzuHoCnn/Z1RiIqRfgj1M8TGdm52HM6Ue+9IyIiF8VARLr2EZlMJmuViOsRERGRXhiISL9AlK5VhLgeERER6Y2BiPSfaZbXWL352EWYzTzRKxEROR8DEem4WrUWiOqXDYGHmwlnEjNwKiFd330jIiKXxEBEup7PTPh6uaNOrBaS/th/Vs89IyIiF8VARLpXiESHOtHq+s2le3Hw7OX7iYiInIGBiHTvIRJPtqqM2yqHISUzB4O/2oLE9Cz99o+IiFwOAxEZIhB5uLtheu9bERvsg8PnUzB63jbk5rLBmoiInIOBiHScdm9//rLwAG980q8JvDzcsHLfWby/8oA++0dERC6HgYiczydYu94xH5jeHPjlZeDQb0BWOuqVDcak7vXUwxKIlu+O03dfiYjIJTAQkfNV7wRUvBMwuQHn9gHrPgS+7g68XR04sho9G5fFwNsrqk3HfLsdW49zwUYiIipeJjNXwitQYmIigoODkZCQgKCgvBlSdPPS4oHDfwAHVwIHfwWSTgOBMcDQtcjyDsGALzZi7aEL8Pdyx+xBzdC0Ypjee0xERKX0+M0KEenHNxSo0x24/0Pgqa1AeDUtFP30LDzd3fD5gCa4vUq4mnnWf6aEo/N67zEREZVSDERkDF5+QI9PAJM7sOv/gJ3fwc/LA18MbIpW1csgLSsHj87ahNX/nNN7T4mIqBRiICLjuKUx0Oo57eulzwCJp+Dj6Y5P+zVGu5qRyMjOxeNfbsbKvWf03lMiIiplGIjIWFo9C8Q20qbk/zgCMJtVKPq4b2N0qhONzJxcDP56C77ZeFzvPSUiolKEgYiMxd0T6P4J4OEDHFoJbJ6p7pa1iab1boQet96CnFwzxi7ciSk/7+PijURE5BAMRGQ8ZWoA7SdoXy8fByScVF9Ko/U7DzbAqPbV1O2P/jiEkfP+RnpWjp57S0REpQADERlTsyeB8i2ArFRg9VvWu00mE0a1r463H2wAT3cTluw4jb6fb8DFlExdd5eIiEo2QweiSZMmoWnTpggMDERkZCS6deuG/fv3223Tpk0bdZC0vQwZMsRum+PHj6Nr167w8/NTz/Pcc88hOzvbyT8NFYmbG9DuVe3rv/8HXDxi9/ADjcviy0HNEOjjgc3H4nHfh39h96kEffaViIhKPEMHolWrVmH48OFYv349VqxYgaysLHTo0AEpKSl22z3xxBM4ffq09TJlyhTrYzk5OSoMZWZmYu3atfjyyy8xe/ZsjB8/XoefiIqkQgugyl1AbrZdlcji9ioRWDj0dlQI98PJ+DT0/Hgtfvj7X112lYiISrYStVL1uXPnVIVHglKrVq2sFaKGDRti6tSp+X7PsmXLcM899+DUqVOIiopS982YMQMvvPCCej4vL68CX5crVevo5Bbg87u003wM3wREVL1qk4TULDw9/2/8sV9bo+jRlhXxUpdaqueIiIhcV2JpXalafiARFmZ/Coc5c+YgIiICdevWxdixY5Gammp9bN26dahXr541DImOHTuqN2n37t1O3Hu6IWUbA9U7A+ZcYNXkfDcJ9vPEzAFN8dRdWliateYo+ny+AQfOJDl5Z4mIqKTyQAmRm5uLUaNGoWXLlir4WPTu3RsVKlRAbGwsduzYoSo/0me0cOFC9XhcXJxdGBKW2/JYfjIyMtTFQsIT6ajtS8A/y9Tq1bjzGSCy1lWbuLuZ8EyHGqh7SzCe+XY7Nh65iLvfW42OdaIwrE1VNCgXosuuExFRyVBiApH0Eu3atQt//fWX3f2DBw+2fi2VoJiYGLRr1w6HDh1ClSpVbriZe+LEiTe9z+QgMfWBWvcBexcBv78JPPz1NTftWCca1UYEYMrP+/Hz7jj8svuMutxRNQKP31lJ9R3JmkaGIc3iGYlATAO994SIyKUZ6MhwbSNGjMCSJUvw+++/o2zZstfdtnnz5ur64MGD6jo6Ohpnztif6sFyWx7Ljwy7yfCc5XLixAkH/SR0U1UimLRQdHrHdTetXCYAM/o1xorRrdRCjlI9+uvgeQyctQmNXluuTv/x9fpjOHHx8tCqLrIzgS86AZ+1A+KP6bsvREQuztCBSPq9JQx9//33+O2331CpUqUCv2fbtm3qWipFokWLFti5cyfOnj1r3UZmrElzVe3atfN9Dm9vb/W47YV0JsNkdXtqXy8aAexfBuRkXfdbqkUF4t2HGmLVc20w8PaKiAjwRkpmDn7dewbjftiFO6f8rqbr/7wrTp8Vrw/9BiTHAblZwIHlzn99IiIqGbPMhg0bhrlz5+LHH39EjRo1rPdLx7ivr68aFpPHu3TpgvDwcNVDNHr0aFVFkplolmn3MgtNeoxkOr70DfXr1w+PP/443nzzzULtB2eZGcT5g8And2qLNQr/MkC9B4GGvYHoegV+u4SePacTseqfc+qy5Vi8Og2IqB4VoHqN7qkfAw9nzU777jFg13fa19I43nuec16XiMhFJBbh+G3oQCSLLOZn1qxZGDhwoBrK6tu3r+otkrWJypUrh+7du+OVV16x+8GPHTuGoUOH4o8//oC/vz8GDBiAyZMnw8OjcC1UDEQGcv4AsGU2sGM+kKJNs1fq9ADumwZ4BxT6qS4kZ6gZaV+uPYqkDG2hTlnTqG/zCri/YSwig3xQbDJTgLeqXg53nv7AC0cAD+/ie00iIheTWFoCkVEwEBmQDJcdXAlsnwvsW6ot3hhZB3jkf0BY5SI9VWJ6Fr5edwwz/zpiPQWImwm4o1oZ9Gh0CzrUiYKfl4PnH8iMuf97DAitCGSlAclngP6LgMqtHfs6REQuLJGByLEYiAzu+Hrg2/5aqPAJAR6YCVRtX+SnSc3MxsKt/2Lh1pPYevyS9X5pyvbzdFez0yyX8mF+eLJVFbSsGn7NSuZ1zX0Y+OdnoNVz2slrt38DtHwauPu1oj8XERHli4HIwRiISoDE08C3/YCTm7TZaO3GawHDzf2Gnu7o+RR8//e/6nL8OrPRmlUKwzN3V0fzyuGFf/LUi8Db1bSq1rANwJldWrUoqi4wdM0N7S8REV2NgcjBGIhKiOwM4KfngK1fareDywPNHgca9QP87Fc3Lyz53yMuMR3pWbnIzNYuGdk5WLLjNOZuPK5uC6kUta8VBfm/yZz3fVI5ign2QaUIf1QM94evV1442zwLWDIKiKoHDP0LSLkAvCVrZpmx9YF1+HJXBqpHBWJI6yqqOkVERDeGgcjBGIhKGGm6/nUikHZRu+3hC9R/ELhtWL6rXN+o0wlp+Oj3Q5i36Tiycgr+3yg22AdVIgPwZuJYlEvYgqy2E+DZejSyc3KR/GErhMTvxLNZT+K7HK2P6K6akZj6SEME+Xg6bJ+JiFxJIgORYzEQlUDSqCyNyxs/AeJ2ave5ewGP/qydH82BTsanYvaao6qSJFUhKepIXUcykjx2+FwKEtK0NZOicQFrvUfCzWRGq6xpiCxbFWeS0vFA4ld42uN7LM1tgZ9rTcLy3XHIyM5F5TL++Lx/E7XYJBERFQ0DkYMxEJVg8ustTde/vQ4cWwOEVQGG/Al4+Tt1N+JTMnH4fDLMaz9Ek/3vYJupFrqljbM+3sb3MGabX0GuTwjcnj+MnaeSMfjrzTidkI5AHw9M69UIbWpEqnWTkjOykZSehbTMnMsBLO860McToX6eN9boTURUyjAQORgDUSmQFg98dDuQdApo8hhwz7v67McnrYHT22Du8jZOVOmDDUcuwM1kQpc6ZeD7XjUgIwF4fCVQtgnOJqVj6P+2qgUkJd/ITDdZabsgwb6eqm+pslzK+KNe2RA0rRjq+KUDiIgMjoHIwRiISonDfwBf3a993XsBUL2D81fa/rAxYHIHnv0H8I+wf1yWDtjzI9BmLNDmRXWXNHBPWLQb32y0P5+et4ebtUlbVuCW/4tzzeZrBiZPdxMalQ9VJ7ltUjEU8SlZOHA2CQfPJqtLfGom6t0Soh6T8FT3lmB4e9zYDD0iIqNgIHIwBqJS5OexwPqPAP9IYNh6wD/cvu9IhtduaQz4FMPn/PubwKr/amsk9f2/qx/f8iWweCRQtinw+K92D/17KU01Xwd4eyDAx+OaYSU9KwdHL6TgyLkUHD6fosLOxiMX1fcXhay1VLVMgKo2WS9+nip8SehKy8xW19LnFBHghbKhfigb4otbQn0RFeSjAps8h4ebCZ4ebqq65bRTohAR3cDxmzV0ci3tXtVOqnpunxY+Hv4fcHavNlVfFkdMT9BWj5b7C3F+tCKtk7TuI+3r+o/kv03Vdtr1v1u0tYpslgq4JcS3UC/j4+mOmtFB6mIhf/Mcu5CKNYfOY83B89h+IgGRQd4q8FSLCkDVyAA1k23biUvYdPQiNh+Nx4WUTHXeN0eRYCSLWcpQnlqGIMIfIX6e6n4ZMvRwN8HDzU2FPdkXCWBBvtcOfuJMYjq2n7iEvaeTEBXkjdY1yiAmuHDvU3GS3q45G47hf+uPoWnFMLx2f93LSy4QkWGxQlQIrBCVMqd3AJ/dpZ1lvkxNLRxZyHCWOQfw8AHumQo07OWY11wwENj9vVZ9emzFtReMnH4bcG4v8MAsoG4P6EH+SZDqkixImZiWpS4ySy4xPVv1Mvl7ecDPy131JMlQ3NmkDJyMT1NVqH/jU9Xt7BwzsnJykZ138twb5ePphnB/b4QHeCHc3wvhAd5qX3acvIQziRlXbV8zOlAFIxkalGqaDCPm5EI1o0voig7yQXSwDzyLoVolK51LCPp09WGcT86026dP+zVB+XA/h78mEV0fh8wcjIGoFPrrPeDXCdrXbh5Ajc7ArQOB2EbA908CB1dojzUZBHSafPmkqxnJwKVj2iKQwWUBvwjArYCD64FfgTk9AZMbMHgVEFP/2tv+8jKw7kOgYV+g23SUdPLPS2ZOLi4kZ6rVvyVoHTmfor5OycxWQUVCk1zLIpcyg04CmJxst6B/mWRWXbXIQNSJDcKRCymqwlWYf80k1EUGeqtqUpCvNgwory/hSb5fqlRlArwREeilriWESbiS6ptUenw9tTB7PjlDNb6fS8pQswEXbTulKmuibKgvejUrj1lrjqhwJBWvD3o1QuvqZRzyvhJR4TAQORgDUSmUmwOsmapVhBr0AgKjbB7LBVZPAf6YrFaPRkQNbZq+BKHUC/bPI2sbBd2ihaMaXYDmQ+wDkvQlTW+ufe9tw4FOb15/v2Q47+vugKc/MGgZENMArkhCioSihNQsXEjJUIFKTrx7PiVDDaPVLxusgpDtzDlZ2mD1gXNY9c85NTNPQo6s9O0uSxK4mVTgkrWiLKuLFwcZFhzRtiq633qLqkLJ4p0yU1DCmgQxOc1L25qR1uAmIUwW9ZRlFKQCJ9dJ6dnw9/ZA3dgg1IoJUkHsStJsf+JiGv45k4R9pxOxLy4J+88kISUjW51OplW1MrijWoTq7SJyZYkMRI7FQOSipLIj5xhLv3yiV8U3VBtSS4rTApOtKncB3T8FAvIqAStfB/58WwtNwzcA3oEFB7WvuwFHVgMB0VpzdUg5B/9grkv+uZMqzqlLaTh1KV0FCAlNbnnBSUKLVKik6iMVoHPJcp2p+oLSsqSZXBrJcyAjgdJMXibQW1WRIoN8VEDrUi/mquG4a80ULAzZt2qRAagdE6QqbTIsKcOTsn+FIcsuNCgbgjB/L+sl1M9L9W5ZKnM5Esqyc1UYS0jLzhsezVI/r5e7mxoWlYZ4+TrIxwNRwT5q6DEqb/hRqmfyM/M0M2REDEQOxkDkwhL+BQ7+CviFA6EVgJDygE+w9lhOFpB0WjtbvTRC//YGkJ2mBZkHZgL+ZYCPW2q9StKkXevewr2mNHZ/0Qk4u0frcRr0sxbCqET7ZuNxzFh1KG9BTRnyM6kVzd3dTaqRXBbgDMy7lorYrn8TrENw+ZGhu+pRAagRHYga0UGoFR2oZvatOXhBVcqkKiWBx1kkD0kwkopWbIgvKoT5qb4pqZpJeJQZiTILUguXuSp0XUzOVD/jxZQMXErLUkOL8r0yY1GuZTJB2TBflAv1U1UzCzlsSVA9cCYJB88lq1DWsmqECmlEthiIHIyBiApFZqt9OwA4v1/rFwoqCyQcB6p3AnrN05pXCktC1ud3awtJVrgD6Lfwch8T6evoX8A/vwB3jL7hkwYXhvzTLI3jO/9NUMNi0r90S97SBnIt1Z7rrUgulZ71hy/g2IUULXTkDTteTM1UFS6pEklVx3It/VSWGX5y8fV0U1UkqUxlZct1Di6lZqnZfTL0GJeQoYYznXUEkZ+3XKivCn3a2lna6XBsSTVNgpFc/L3dkZyerfrSpBIoy0RIQJT3VVu3S1teQmYoSqXL0nAvsx3le+R7JbSlZuaoGY9RgT5qZqTtey7hTqvaparnrhkTpM5ZyJXijYOByMEYiKjQMlOApc8C2+dePrGsDJVJdamo4nZplaLMJKBuT6DH5wU3cFPxSrkAfNBIW1E8qh7Q/0f7taxcjKyNJZUfmVEovVkSniRASECQpR7kcuJiqlr409KQ7i3N6Z7uqhImMwdDZfagv5cKZDJcKUOCMpz576VUFTakV8pyLkBbkjmk+iQhSGY2SnAs7qOZJUBJcJRgaDub0EJOnVMnVutxkyqXrMnl7emmet8kfMrPIt9nGZaVocoQP234VSppEQHeqjcuLUuCXI6avSjvqVTeZHhWtpNlM2Q7fy8PtU8FDVdKwNtzKlFVHS3LacRICAz2UdcywaBShH++/WolHQORgzEQUZH9PQdY8z5wxyigYe+bW137fz2B3GygWgeg/UQgqjaKjcyik/WYNn0u/zwAfb/TGsZJ89NzwMZPL9+OrAMMWHT1quPkUFKpOXkxDSfiU9WwW5Uy2vpZtgfwS6mZWHfoAv48eB6bjlxU98mMQbWYqbeHCmSWda+kgiOBKj0zR51cWWYJxiWkq+BhIUtLyPfJUJ2EGKmu5Ue2kYqdPJ9Urm52qYkbIYFIerwkePl4uKvlKuS9kYuETJmFWdCR3t3NhCpl/FW/Wu3YIFQI91cN/heSM7QJDcmZqromMyjLhvmpYcxyYb6qMibvnVY1lJCYgQBvT62/Lu8iQU+qjvJeObt6xkDkYAxEpKvt84EfhmrrI0lIqf8w0HastoBkUcn/7jK0J+sgeQdp/VCevtoQnRzoZYFK6WGykB6mR5cV69BQiXHuH+Cj27TP4Z73gD/+CyTHAZG1gf6LLjfSU4kkh0K13EMu1HCbRz7N8WcTtaUWJCBFBvqoUCDDaZaDvIS1A2eSsftUAnafSlTDkxlZUkXTVnWXiwQD24Z8qZTJ8N/5JEsTf4YaipMgJqHM30sLc9LkLlUl2QfZ7loBzdbj7ktR3XQS47IfRXhwEOrcolWupNdLwovMgpQwKFW5hHyqcI4mhSzL0Kz83FIplJ/Nsq6ZDIuOu8exf/AxEDkYAxEZ4mD8+3+0c50JN0/g1n5ApdZAVF0grNK1F3u0DOVJ5WfDJ8D5f+wfk3WY5CggFxFWGWj8KLD+Y62HqWwzbWjI6zpTuDOSgN0/ANvmABcOatUsWc6gQkv7YT6ZRXfqb60Pp1xzoEILlBhzHgIO/ALU6Ar0mqudm+7Le7TGegmOAxYDAZF67yXdjEO/axMYYhuipAxXykUNV2ZfDl4SnnxO/Il6K/urbVNbvgi/u8cW2K+253SCGlqTYTUJSVp481ZBRRZHlbQg98uQqAyFypCmVJYssw5l+E22lzXGJLxZLlJdkuHUgshw5IaX2jv0fWIgcjAGIjIMmc228jVtKM2Wpx8QWQuIqA4ExWqXwFhtdty+JfaVH+lr8vTRbltCkKjUCrhtGFCtoxZipJIkPUyy7IAEnEfmAu6e9uFGzv0mIUjCUFbK1fsrs/LkVCXBt2gHG9lvyzIGsoZTr2+0c7sZnWV9KAmPwzYAEVW1+y8cAmZLKDqlrVf1+IrLsxCp5JDD4CpZe+xN7fdSVpMvAaHomjJTgY9vB+KPXP5//qnNDh/+zs01q6HCwgyDSfVMrXyvlnfQ1tuyLGchQ5XytSzxMLBlJYfuIwORgzEQkeEcXgXsXACc2a0FF5nuX5DQStrCkdLTJCevlf/1pXIkwUjNiou5+nuObwC+ul97fqn4dJqkBZsDy7WL7UKVYVWARn211b7lNCVyycjnfGjewVpAkmUFZD2nPgu0MGZUEvxm3Amc3Q00Hwp0lgU7bVw8DMzqqoWi6p214FhSmt+zM4Ft/wP2LwNuG6qto+Vq5P8D+SPjr3cv3ydV0idXF7xumFGtGK/1MMr6Z3I5uVGbmPHAF3A1iQxEjsVARIYmB+yLR4AzO7XrxFPaME7iv9rikTKc0/xJrcpzvWG1a5Ep5t/0utzDZLsYpfQh1b5fC0IyBGb7l6Ks0r1vKbBjvtasLaFHTmAbe6tWmfq2P/DPMq261XdhwcNn8levrAklw3NyTjipht1o8JAgKEOH5w/kXed9Le9feFWgwcNAvQeBwGhgy2xg8dOATwgw8u/8+6n+3apV03IygDZjgTYvwuFkBXUJZZZK26Xj2qllJMgUtVFVfmfkc5HV2GUVdSGh+K5x2nICrjJtXA5/v7wErM878XKbl4C/vwYSTgB1HwB6fl7y3otT27RzNcr/r73ma9XiT1tr/88N/Amo2BKuJJGByLEYiMjlbZurNXYLCSISrmR9pfK32Q+jFYWcD06C1qGVgFcg0P8HoGyTK7bJ1Iardn0H7PvJflhOwpgEo7JNgag62n7JX/YyHGgh4ensPq0aJSfxPbdfCz9ywCuIBITKbYG4HUDKOe2cdhI+rjez8Mdh2tdyIKrRqfDvhYRHCbESYOU69aI2tCjVu/RErRInw5Op56/+Xgmk932oVf0KIu/nvsVaELL0kvlHau/7/p+02zXvAbp9XLjnc6ZLJ4A/39EqotH1tH2Wz14+8xsJLRIwf3oW2DxTu93lbaDZE1pVdFZnLVDcNw24VevDUXKyga2ztT8Smg0Gqt0NQ5H9+yzvd7ZOd+DB2dr9i0cBW2ZpS0U8uerG/jAqDMsfQfLvgkFmpzIQORgDERGAM3u0sCEHIEeRqs/ch4Cjf2pDaZXuBLLTtX9Y5SLDUbanTpGepOByWmN2Vmo+T2i6vI1UUGRhzGuRlcQlREVUy7uurn2vNHxL9eTEhsvbStVo2PqCw9/SZ7QlCySsPfH75V6jK8Uf0w6qUiGTvjDbmX3XI+e4k7/wK7fRlmKQU8PISujh1YCHv9b6yPI78J9YD+z4FtjzA5AWr90vzcMtR2kHdmmYl0qYLCuQk6m9Fz3zfo60i0BqvPZ98loyzCkX+V2Q3hRZBqI4+6YkJEoQkv2TfbuS/BwyVNn2pcKf5kbe7yWjgV3/p/3OqODT7+qTP8vP98Rv2s8olTmpJkm4tpAZnx0nGWctqjUfACvGadXMEZsuN/nL+lnTGmk/d9d3gaaPOf61k84A83oD/27Wfk/vekWrTBdX+CokBiIHYyAiKkYynCZrLclBOz8BUdpfuzKEIVUBqQbIX8JyYDq5SQsUUv2RWV+yYOKVAmO0oCBDh2VqaM3Pcl3QUgLSMC0h4vg67R/3cs0KV4H58l7tZ5HXkxXKJdDJwUKm6MtzHlgBnNt79ffKwVf6uGR/pRleQoa6hGjVGplNKBURD6/L33Nio7Y6uvQvydBju1e1vhepKEmQkcqW9JvZVsTk/ZRZhC2GXR1kTm4G5vfTnq+wZMajBFmpLMkJjvPrRbOQypf8/FL1k5+pyWNAZM38t5WlIGRW5MbPLvfIyazK+g9pVSL57GV4SIYpLe9fy5FAy6e1kzFfy9E1wPdDtLAsJ3fuPkN7zitD5JwHtOql/L6EV7lcQZMAJhMBJEzJMJRfBNBlClCnR9EqVfI7/PdXwN4lWiCV55H1rORaZo3KELMsiXG9YU8JqfKeyuctn9kPw7X36v7p2jC2rQ2fAsueA3zDgKe25P/7n5EMHFsLHP5d+52p95D2uRY0NC2LyM59GEg8qVVWLZM1YhoC932g60mqGYgcjIGIqJhJT48sKSBVITkIqAqErxYMZFisMH9lyj9lEgDUkNi/WrVAQomz11CS8CM9GzL0dS1yIC7fAqjeEajSVqtMSTXmRoZ+Us4D3w0Cjqy69jYyJFn7Pq0vSg6013s/k88CCwdrB0UJGfL+yUHUL1QLPzLUKQdduZaKw5XDj9JULw38cnCXKpxcy4H7n+Vac6/tzEYh4aLFcG14Un4P9i7WloiQExxb+tVk6Yd2465uvpcAKhWJ3/4DHFuj3SeBsv0ErYnYtqIn+/v7G1oVRZ5X1vHq/ok2vJPv+3AOmHGHFmSFzDBs+gTQ+nntPZHw+OOIy+FWGtKlYlT17utXjOT3VCYkLB+nnebnWqTKIkNyMiQqQ9QSNCQESgVTLvJz51cxk/dI1sW68ndJAtgnMjlgj/Z+yh8JEqItQ8wnNmoXqQLakiDe+oVrByNpyP/uMW04WyqpMlx87C9g+XjtDxTZb5nMIaEzun7+v3vyXktFVj5/6d9zIAYiB2MgIqIiObFJm6YvBwnp0QmM0k76K9WTindqzeWOPGGvVAtklpQMw0mwkiCpLmFaNUwOqNerNuRHwoZtNepapBldlnaQ3hE5YBdEVveWA72sVyXfYwk9MktRQqTtUKisYyUVHxUIrhMW5TC2dxGw/BVtqFQxadUwaSqWWY0XDmtN6UKqJ9ITVtAsMqkmSfO/hPIO/wHKVL/6PZLhtdVv2QQJk1bJq95BCwAqdPhpVSAJkBLKVNiTalOYVtXyCtCCrfSIybVUPW2Dprucx9CcfwCSKp8KrGFaIJEwKD9zfqRa+NV91/+ZQypoIV1+jzbP0k4dZPncpJ9KQqZl3TJ5r9dN1/ZNgthDX13+vZY/DH5+Edi98PJzy3NKAK1wu7bfKoRt0IbGhcyIG2MzJOkADEQOxkBEREWWk6X9daxzD4VTJZ7WKjVSqbNezmvvgxxkZY0r2z4fORDKsNjf/wMyky8HI1niQSoKRT0HYFY6sOFjLaTk15clIfHeD4Ba9xT+OeUQWVDlTkLh9nnawp1xOwt+Tgk4tw0B7nwm//4reU3pk5OqqQQ9S2CQtcVkeLLiHVpYlPDi7oEiOfCrVtWS90oqfVKVlaAVVUer0slwnYUMx8kCrRtm5L+EhkXjgVpTen49dlIZ3PSZNingms9h0ipWMlO1838deiJrBiIHYyAiIipGaZe0JRVk6FCqKzc71V16gKSvRnpaZPhUlqKQZn0Z0pJqXXGS11PrdK3Q+npk4oCaJJCihWQZJpXlDQob9uQQLYFLgo8MReqxDEBavNaDdHrb5ZAv1zL0K0OeDR4peL+kiilhUXqUJDRLAJbPutxtWm+gb0ix7DoDkYMxEBEREZXu43cJWU6ViIiIqPi4VCCaPn06KlasCB8fHzRv3hwbN27Ue5eIiIjIAFwmEM2fPx9jxozBq6++iq1bt6JBgwbo2LEjzp49q/euERERkc5cJhC9++67eOKJJ/Doo4+idu3amDFjBvz8/PDFF653sjsiIiJywUCUmZmJLVu2oH379tb73Nzc1O1169bpum9ERESkvyIuYFAynT9/Hjk5OYiKsp9uKbf37dt31fYZGRnqYtulTkRERKWXS1SIimrSpElqmp7lUq5cIU8YSERERCWSSwSiiIgIuLu748yZM3b3y+3o6Oirth87dqxas8ByOXHiinP1EBERUaniEoHIy8sLjRs3xsqVK6335ebmqtstWrS4antvb2+1gJPthYiIiEovl+ghEjLlfsCAAWjSpAmaNWuGqVOnIiUlRc06IyIiItfmMoHo4Ycfxrlz5zB+/HjExcWhYcOG+Pnnn69qtCYiIiLXw3OZFQLPZUZERFTy8FxmREREREXAQEREREQuz2V6iG6GZVSRCzQSERGVHJbjdmG6gxiICiEpKUldc4FGIiKiknkcl16i62FTdSHImkWnTp1CYGAgTCaTw9OrBC1Z/JEN287F914/fO/1w/deP3zvnU8ijoSh2NhYdQ7T62GFqBDkTSxbtmyxvgYXgNQP33v98L3XD997/fC9d66CKkMWbKomIiIil8dARERERC6PgUhnct60V199VV2Tc/G91w/fe/3wvdcP33tjY1M1ERERuTxWiIiIiMjlMRARERGRy2MgIiIiIpfHQEREREQuj4FIR9OnT0fFihXh4+OD5s2bY+PGjXrvUqkzadIkNG3aVK0yHhkZiW7dumH//v1226Snp2P48OEIDw9HQEAAevbsiTNnzui2z6XV5MmT1Urvo0aNst7H9774/Pvvv+jbt696b319fVGvXj1s3rzZ+rjMpxk/fjxiYmLU4+3bt8eBAwd03efSICcnB+PGjUOlSpXU+1qlShW8/vrrdufS4ntvTAxEOpk/fz7GjBmjpmBu3boVDRo0QMeOHXH27Fm9d61UWbVqlTrgrl+/HitWrEBWVhY6dOiAlJQU6zajR4/G4sWLsWDBArW9nKalR48euu53abNp0yZ88sknqF+/vt39fO+LR3x8PFq2bAlPT08sW7YMe/bswTvvvIPQ0FDrNlOmTMEHH3yAGTNmYMOGDfD391f/BklIpRv33//+Fx9//DE+/PBD7N27V92W93ratGnWbfjeG5RMuyfna9asmXn48OHW2zk5OebY2FjzpEmTdN2v0u7s2bPyZ5p51apV6valS5fMnp6e5gULFli32bt3r9pm3bp1Ou5p6ZGUlGSuVq2aecWKFebWrVubn376aXU/3/vi88ILL5jvuOOOaz6em5trjo6ONr/11lvW++Tz8Pb2Nn/zzTdO2svSqWvXruZBgwbZ3dejRw9znz591Nd8742LFSIdZGZmYsuWLapManu+NLm9bt06XfettEtISFDXYWFh6lo+B6ka2X4WNWvWRPny5flZOIhU6Lp27Wr3Hgu+98Vn0aJFaNKkCR588EE1VNyoUSN89tln1sePHDmCuLg4u/dezvckQ/d872/O7bffjpUrV+Kff/5Rt7dv346//voLnTt3Vrf53hsXT+6qg/Pnz6tx5qioKLv75fa+fft026/SLjc3V/WvyFBC3bp11X3yD5OXlxdCQkKu+izkMbo58+bNU0PCMmR2Jb73xefw4cNq2EaG5V966SX1/o8cOVK93wMGDLC+v/n9G8T3/ua8+OKL6qz2Eu7d3d3Vv/VvvPEG+vTpox7ne29cDETkUpWKXbt2qb/WqPidOHECTz/9tOrdkokD5NzwLxWiN998U92WCpH87kvPigQiKj7ffvst5syZg7lz56JOnTrYtm2b+kMsNjaW773BcchMBxEREeovhytn08jt6Oho3farNBsxYgSWLFmC33//HWXLlrXeL++3DGFeunTJbnt+FjdPhsRkksCtt94KDw8PdZHGaWkmla/lL2K+98VDZi/Vrl3b7r5atWrh+PHj6mvL+8t/gxzvueeeU1WiRx55RM3s69evn5o8IDNeBd9742Ig0oGUrRs3bqzGmW3/opPbLVq00HXfShuZ3iph6Pvvv8dvv/2mpsLaks9BZuLYfhYyLV8OHPwsbk67du2wc+dO9Rey5SJVCxk6sHzN9754yLDwlctLSE9LhQoV1Nfy/4EcfG3fexnmkRlPfO9vTmpqquoJtSV/AMu/8YLvvYHp3dXtqubNm6dmFcyePdu8Z88e8+DBg80hISHmuLg4vXetVBk6dKg5ODjY/Mcff5hPnz5tvaSmplq3GTJkiLl8+fLm3377zbx582ZzixYt1IUcz3aWmeB7Xzw2btxo9vDwML/xxhvmAwcOmOfMmWP28/Mz/+9//7NuM3nyZPVvzo8//mjesWOH+f777zdXqlTJnJaWpuu+l3QDBgww33LLLeYlS5aYjxw5Yl64cKE5IiLC/Pzzz1u34XtvTAxEOpo2bZo6GHh5ealp+OvXr9d7l0odyfz5XWbNmmXdRv4RGjZsmDk0NFQdNLp3765CExV/IOJ7X3wWL15srlu3rvrDq2bNmuZPP/3U7nGZ/j1u3DhzVFSU2qZdu3bm/fv367a/pUViYqL6HZd/2318fMyVK1c2v/zyy+aMjAzrNnzvjckk/9G7SkVERESkJ/YQERERkctjICIiIiKXx0BERERELo+BiIiIiFweAxERERG5PAYiIiIicnkMREREROTyGIiIiG6QyWTCDz/8oPduEJEDMBARUYk0cOBAFUiuvHTq1EnvXSOiEshD7x0gIrpREn5mzZpld5+3t7du+0NEJRcrRERUYkn4kTOH215CQ0PVY1It+vjjj9G5c2f4+vqicuXK+O677+y+f+fOnbjrrrvU4+Hh4Rg8eDCSk5Pttvniiy9Qp04d9VoxMTEYMWKE3ePnz59H9+7d4efnh2rVqmHRokVO+MmJyNEYiIio1Bo3bhx69uyJ7du3o0+fPnjkkUewd+9e9VhKSgo6duyoAtSmTZuwYMEC/Prrr3aBRwLV8OHDVVCS8CRhp2rVqnavMXHiRDz00EPYsWMHunTpol7n4sWLTv9Ziegm6X12WSKiGzFgwACzu7u72d/f3+7yxhtvqMfln7chQ4bYfU/z5s3NQ4cOVV/L2d9DQ0PNycnJ1seXLl1qdnNzM8fFxanbsbGx6kzl1yKv8corr1hvy3PJfcuWLXP4z0tExYs9RERUYrVt21ZVcWyFhYVZv27RooXdY3J727Zt6mupFDVo0AD+/v7Wx1u2bInc3Fzs379fDbmdOnUK7dq1u+4+1K9f3/q1PFdQUBDOnj170z8bETkXAxERlVgSQK4cwnIU6SsqDE9PT7vbEqQkVBFRycIeIiIqtdavX3/V7Vq1aqmv5Vp6i6SXyGLNmjVwc3NDjRo1EBgYiIoVK2LlypVO328icj5WiIioxMrIyEBcXJzdfR4eHoiIiFBfS6N0kyZNcMcdd2DOnDnYuHEjZs6cqR6T5udXX30VAwYMwIQJE3Du3Dk89dRT6NevH6KiotQ2cv+QIUMQGRmpZqslJSWp0CTbEVHpwkBERCXWzz//rKbC25Lqzr59+6wzwObNm4dhw4ap7b755hvUrl1bPSbT5H/55Rc8/fTTaNq0qbotM9Leffdd63NJWEpPT8d7772HZ599VgWtBx54wMk/JRE5g0k6q53ySkRETiS9PN9//z26deum964QUQnAHiIiIiJyeQxERERE5PLYQ0REpRK7AYioKFghIiIiIpfHQEREREQuj4GIiIiIXB4DEREREbk8BiIiIiJyeQxERERE5PIYiIiIiMjlMRARERGRy2MgIiIiIri6/wfhlwwFUxE0bgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- Optional: Plot training history ---\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MAE Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b4e38cbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4e38cbe",
        "outputId": "09b0aebe-647c-4334-e52b-10e8f1a3c488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "LSTM MAE: 46.47\n",
            "LSTM R² Score: 0.994\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Load best model ---\n",
        "best_model = load_model(\"best_lstmv1_model.keras\")\n",
        "\n",
        "# --- Evaluation ---\n",
        "y_pred = best_model.predict(X_val).flatten()\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "print(f\"\\nLSTM MAE: {mae:.2f}\")\n",
        "print(f\"LSTM R² Score: {r2:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "72c7f412",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72c7f412",
        "outputId": "da3db77e-1a49-4af5-e259-f278b5571bcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "LSTM MAE: 46.50\n",
            "LSTM R² Score: 0.993\n"
          ]
        }
      ],
      "source": [
        "# --- Testing ---\n",
        "y_pred = best_model.predict(X_test).flatten()\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nLSTM MAE: {mae:.2f}\")\n",
        "print(f\"LSTM R² Score: {r2:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bfceb24a",
      "metadata": {
        "id": "bfceb24a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "depi",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
